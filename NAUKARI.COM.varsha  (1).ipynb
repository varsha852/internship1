{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8310d2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\arti\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\arti\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n"
     ]
    }
   ],
   "source": [
    "# let's first install the selenium library\n",
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1384a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now import all the required libraries.\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bf17b8",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "463601dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\arti\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68e7002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naukri.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d339d21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"77c19a19-9e78-4559-8445-db0cb78b5bc9\")>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_job = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input\")\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f517455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_job.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "857ee462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for job location bar\n",
    "search_loc=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "162c81f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"8f1d0b1a-e533-4465-94bd-182db46608ee\")>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_btn= driver .find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[5]/div/input\")\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c4152fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn= driver .find_element_by_xpath(\"//html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50a774e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"909a89ea-f519-4fa2-8c8d-f82e63b74bf4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"dad9f262-75c0-4dcf-a4e3-37b9a1f09913\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"354cd706-5f3b-4adb-b2a8-c48579a4e80e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"4d2fb255-81a0-4c8a-aa85-2ddee441f3ec\")>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so let's extract all the tags having the job titles\n",
    "title_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tags[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c184e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst',\n",
       " 'Data Analyst / Product Analyst / Business Analyst',\n",
       " 'Data Analyst / Business Analyst',\n",
       " 'Data Analyst / Business Analyst',\n",
       " 'Data Analyst 1',\n",
       " 'Financial Data Analyst',\n",
       " 'Data Analyst III',\n",
       " 'data analyst/ data analytics / Business analyst- SQL/Python/SAS',\n",
       " 'Sr Data Analyst - SQL/Python',\n",
       " 'Senior Data Analyst - SQL/Tableau']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the text of the job title  from the tags\n",
    "job_titles=[]\n",
    "for i in title_tags:\n",
    "    if i.text is None:\n",
    "        job_titles.append('Not')\n",
    "    else:\n",
    "        job_titles.append(i.text)\n",
    "job_titles[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "902b372d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"59a8438a-78cc-47d2-b4fa-a95d31433a50\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"d0c36ddd-5c73-4869-a33f-37ae422fc7be\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"3ecbe9e2-b375-4b41-a3f3-970ced0285d7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"29c348ca-ea57-4252-ab53-a805eb05b405\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"620005b6-8dfa-498a-a3c3-94b4598b883c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"c322fa86-88a5-4fbd-8a68-3c0c8d2d42d1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"c66d9404-1211-48c2-a2a2-345bfee0a250\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"3f83e871-36ba-4584-886b-2335237d2a3b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"a286ca99-d7d7-4c34-a5f8-cc87bce61300\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"41447a0d-cab2-44da-9be8-15576deb2e89\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"7bf1fa51-b6c8-4846-91dc-11217db30709\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"d02730d3-7efe-460a-bead-4fb1972fdcc1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"35ce0530-4b04-4a64-a4e9-7d793ff0115d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"c3dbb23d-ea02-4418-b69b-ca29bbea19dd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"a452fe70-5cfa-487b-a02d-f0068537b79c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"1d6d3e0b-cbbb-4c8d-808a-6f98b95fab7e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"5132e7fb-cf97-4557-918e-f9eb1b8ee879\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"1082b4a4-d75b-4444-b8e1-7f26c0ee01f8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"8723eacd-3697-4ddd-9350-329ac48ed34d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"01e2c5de-6b9d-4ecd-a797-49c9e9ac2041\")>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets extract all the tags having company names\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8b7d900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Encora',\n",
       " 'Benchire',\n",
       " 'METRO Cash & Carry',\n",
       " 'METRO Cash & Carry',\n",
       " 'Optum',\n",
       " \"Moody's\",\n",
       " 'Walmart',\n",
       " 'Leading US MNC into Analytics',\n",
       " 'AVE-Promagne',\n",
       " 'Global Employees']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will extract the text from the tags by looping over these tags\n",
    "companies_names=[]\n",
    "\n",
    "for i in company_tags:\n",
    "    companies_names.append(i.text)\n",
    "companies_names[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bdb89cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"a97e1b06-7716-47e2-b3e9-de7c16dcc6e4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"a61334ae-0422-4bcb-aacd-166123fa3d59\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"0fbec134-425f-4d47-974f-ad48094c8dc7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"0b946491-c31e-452a-bc18-56e457c3d257\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"0a77d123-711a-4825-bf7a-615051a1d9a0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"c3ce4bfd-b92a-4a84-83db-c7f01912ca38\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"aeb85ec9-eb55-4740-956c-db111bf686f7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"399c4652-815f-4160-bf9f-1517d7827cc8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"0e0bf70e-1340-4483-843e-c6c4d126c3b7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"393d1de3-7bc9-47bd-86ca-e9fa6232437c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"356cb3bd-24ea-4552-96b5-f5dfa4b09933\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"c251c0a9-1a4d-4b82-be5f-1ab70a86da8a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"dc92a689-9f00-499f-a876-1dc5c5ff0c41\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"7d7acacb-31a3-4dbb-9950-1688f9dd0582\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"becc3dc6-74bb-4f82-93ee-4e5ee087a014\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"3cdd43d2-5702-4ee5-b072-3bc4015b930d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"eb3f3c51-9d9d-4d9d-ac36-95d74a85a522\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"5233b1c2-a4cd-4b8d-9d0f-d67e65dd813b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"209d7ba3-62f7-41f1-bdc0-ca64488d16b6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"1a3806d4-3972-46b7-afae-b39269cff58c\")>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so lets extract  all the tags having the experience required data\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience'] //span\")\n",
    "experience_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b47c780b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5-10 Yrs',\n",
       " '2-5 Yrs',\n",
       " '3-8 Yrs',\n",
       " '3-8 Yrs',\n",
       " '4-9 Yrs',\n",
       " '1-3 Yrs',\n",
       " '3-7 Yrs',\n",
       " '2-7 Yrs',\n",
       " '3-8 Yrs',\n",
       " '7-12 Yrs']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no we will extract the text  from these tags only by one by looping over these tags\n",
    "experience_list=[]\n",
    "for i in experience_tags:\n",
    "    experience_list.append(i.text)\n",
    "experience_list[:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffad9011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"02672bef-fb05-498e-8c77-e09ecdad6283\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"7d6c0cb0-e85a-45ac-afab-f8465f01e20d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"8bc1cd53-efa9-40cc-b50f-9df8510d4793\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"ef824ad5-79f5-431e-8578-e61ea0ddb7ea\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"7a9995e2-ac94-44aa-aac2-be5e2fa3d2e6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"aa443653-3f44-4bb1-8b50-b64864665e20\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"cb0d50dd-1141-4e4d-993a-b1c175ca6a7e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"bafd7586-3016-4d84-b70a-0ec1f3399fc6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"456c58bc-6ea6-455f-a154-79701bbe2aa4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"36e1ae7b-0aba-47a2-a084-1393040fde23\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"42351966-02f7-4d0d-b3bc-ed11238543ef\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"aeeb7729-0fd8-4750-8fa0-8f48c500243a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"54127234-642c-45ef-a44d-087839021b24\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"1e9c8480-7aab-4df4-9e22-006f3d3865d6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"03d74b3d-9cea-4525-ba96-51e095c59ee1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"c915b1b5-75eb-4979-b720-4cde78c9b381\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"8f5abf83-1281-4b23-9df5-861c88b2a72c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"3c91cc17-7b85-45df-9235-d7a0f150c6bc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"dede1d58-86e0-4dfa-a812-6355a9e9ced8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"75a5f35f-c22e-4b3c-937d-ca45b33d6762\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"8000646f-23de-42de-ae6e-c80266636b05\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"0b9f670e32585ffe6565bc36b4b9daf8\", element=\"16538a43-7419-4579-8ac9-df414d8a7012\")>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "locations_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f21ff7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR',\n",
       " '(WFH during Covid)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi / NCR',\n",
       " '(WFH during Covid)']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_list=[]\n",
    "for i in locations_tags:\n",
    "    locations_list.append(i.text)\n",
    "locations_list[:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb9d8c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#So lets check th length of ech element.\n",
    "print(len(job_titles[:10])),print(len(companies_names[:10])),print(len(experience_list[:10])),print(len(locations_list[:10]))\n",
    "10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94de290f",
   "metadata": {},
   "source": [
    "# Creating a DataFarme for the Data Analyst jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9b47bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles[:10]\n",
    "jobs['company']=companies_names[:10]\n",
    "jobs['experience_required']=experience_list[:10]\n",
    "jobs['location']=locations_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3440b677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Encora</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst / Product Analyst / Business Analyst</td>\n",
       "      <td>Benchire</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>METRO Cash &amp; Carry</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>METRO Cash &amp; Carry</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst 1</td>\n",
       "      <td>Optum</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Financial Data Analyst</td>\n",
       "      <td>Moody's</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst III</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data analyst/ data analytics / Business analys...</td>\n",
       "      <td>Leading US MNC into Analytics</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sr Data Analyst - SQL/Python</td>\n",
       "      <td>AVE-Promagne</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst - SQL/Tableau</td>\n",
       "      <td>Global Employees</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "      <td>(WFH during Covid)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1  Data Analyst / Product Analyst / Business Analyst   \n",
       "2                    Data Analyst / Business Analyst   \n",
       "3                    Data Analyst / Business Analyst   \n",
       "4                                     Data Analyst 1   \n",
       "5                             Financial Data Analyst   \n",
       "6                                   Data Analyst III   \n",
       "7  data analyst/ data analytics / Business analys...   \n",
       "8                       Sr Data Analyst - SQL/Python   \n",
       "9                  Senior Data Analyst - SQL/Tableau   \n",
       "\n",
       "                         company experience_required  \\\n",
       "0                         Encora            5-10 Yrs   \n",
       "1                       Benchire             2-5 Yrs   \n",
       "2             METRO Cash & Carry             3-8 Yrs   \n",
       "3             METRO Cash & Carry             3-8 Yrs   \n",
       "4                          Optum             4-9 Yrs   \n",
       "5                        Moody's             1-3 Yrs   \n",
       "6                        Walmart             3-7 Yrs   \n",
       "7  Leading US MNC into Analytics             2-7 Yrs   \n",
       "8                   AVE-Promagne             3-8 Yrs   \n",
       "9               Global Employees            7-12 Yrs   \n",
       "\n",
       "                                            location  \n",
       "0                                Bangalore/Bengaluru  \n",
       "1                   Bangalore/Bengaluru, Delhi / NCR  \n",
       "2                                 (WFH during Covid)  \n",
       "3                                Bangalore/Bengaluru  \n",
       "4                                Bangalore/Bengaluru  \n",
       "5                                Bangalore/Bengaluru  \n",
       "6                                Bangalore/Bengaluru  \n",
       "7                                Bangalore/Bengaluru  \n",
       "8  Gurgaon/Gurugram, Bangalore/Bengaluru, Delhi /...  \n",
       "9                                 (WFH during Covid)  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3158dd",
   "metadata": {},
   "source": [
    "We can see that we have created the datset named jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1091d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d6eafa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef3f20e",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59acd27",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "139568ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\arti\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1867ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naukri.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "001f2a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"bc760210-3331-4a1a-9177-bed74be82997\")>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_job = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input\")\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "07d08dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09660704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding element for job location bar\n",
    "search_loc=driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "search_loc.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "435db224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"8bef4d9d-0dc0-4e83-b472-3ed441e579fc\")>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_btn= driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa8bd40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn= driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[6]\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5fc5183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"80dd7568-c979-4d15-8288-bf4376936e21\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"b7cdd225-94c4-484b-b5a4-a021f4bae65b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"0d5fd260-4b26-49d7-a178-0a9f7cb233ed\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"05e59bbb-cbd6-4772-915f-fdf073de0b74\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"9d74fd5b-7736-43a1-a8f4-2bd9a9dbeca4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"f86485ee-ae60-4706-8a34-d01459444759\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"78eae825-1090-4a42-8ac3-f5375425fd51\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"2a03eb5f-4392-4e75-a42b-3b4aeb779103\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"61932e56-b3ca-444b-991a-0bd6314b8bc0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"22746c70-0e6c-4cfa-9a14-f987faab861f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"06d592ff-60a7-448d-98ee-95b04ef61a81\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"061c8f13-0db1-4c98-b502-c73f23fc8b11\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"8667a56a-64f3-4dbd-8312-8bfab76bdc9c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"f54871af-8b0a-4381-8af6-a5cb37664125\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"620c205a-d955-40ea-a8f8-8a4d89ffe1b3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"858dbb49-05c6-4aae-a9a3-85fc6d16c858\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"0937d24c-491d-48f0-8aae-4a46e1c1842f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"51ca0377-0b37-4092-9a75-857614edbfcd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"37197e5c-eb5f-4377-aa19-4c3dc592383f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"ad111e26-8ef1-4f4d-bf34-e076c2d8c328\")>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so let's extract all the tags having the job titles\n",
    "title_tag=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b86d4c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Applied Data Scientist / ML Senior Engineer (Python / SQL)',\n",
       " 'Data Scientist',\n",
       " 'Principal Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Expert Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Sr Data Scientist']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the text of the job title  from the tags\n",
    "job1_titles=[]\n",
    "for i in title_tag:\n",
    "    if i.text is None:\n",
    "        job1_titles.append('Not')\n",
    "    else:\n",
    "        job1_titles.append(i.text)\n",
    "job1_titles[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50eafdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"918f231f-95bb-4ff0-9080-56e685e9034c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"04d3a2a2-0a7d-43dc-983b-791be18c75ba\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"4e6f344a-b49d-4b74-917c-74b7c844ddf7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"89348a7d-6340-4c0e-9e2b-28955a027193\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"9b2d13d3-b527-41d6-9576-ce1c79e6fef4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"76f4bc05-a170-42a6-abd1-0bb4df72e6dd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"6b84d967-285a-4e00-aec8-ba0af648fc7c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"9249a854-b733-4467-bd94-3bd946782b21\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"47382c2f-b11a-4d4e-9821-3d84153885db\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"c626025f-ec36-489e-b63b-f4b44d851939\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"b35dd89c-431d-4e3e-b20b-bd1d74754799\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"aff83430-0ac2-40c2-b285-7b4680d67a90\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"6e079c81-0a87-490f-b01e-01a3510cc88c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"8c0e20a0-c31d-4830-b3f0-35b82de9f18a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"c99e6f8c-b023-434c-81a3-297c44b45e65\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"70f58f38-f819-43b5-a3c1-1cbfb2722210\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"71ac1bc8-0d8a-4854-9f15-6097eadc60d7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"0ddf2f01-b2f6-4a19-862e-5d5d35598867\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"5da11d15-9f8e-46fa-9e9c-92634bd51b87\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"8bad4072-d5b1-41df-bdd9-acecda195026\")>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets extract all the tags having company names\n",
    "company_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "824397e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UPL',\n",
       " 'Walmart',\n",
       " 'SAP India Pvt.Ltd',\n",
       " 'UPL',\n",
       " 'UPL',\n",
       " 'Walmart',\n",
       " 'Walmart',\n",
       " 'UPL',\n",
       " 'Ericsson',\n",
       " 'Target']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will extract the text from the tags by looping over these tags\n",
    "companies_names=[]\n",
    "\n",
    "for i in company_tags:\n",
    "    companies_names.append(i.text)\n",
    "companies_names[:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ded0d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"466a3f59-a53c-4186-bf9e-82e4be2d4eb5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"43e61311-6e57-4de0-be3b-11289307c06c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"f7e1bcfb-2e4b-40ff-a715-52cd1628ef74\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"826cc50f-d695-4a43-9898-9b279c72c0b6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"45940c20-1274-42d1-8f8e-d711ce69be3b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"37ec25bb-63b5-44b1-8fba-180feabfcd1b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"cb8a5683-9e93-405a-96b4-2d47eeadda9d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"70b54c2c-8b2b-4d7a-b38d-8743f49a6997\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"ff49469f-2f8b-4312-945e-6a1b4eacc8a7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"29305450-16e5-4739-af9e-17f1dea837b1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"2d10a2f0-f3a1-4742-b143-6f83df2e7140\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"88180656-1d53-4f31-8f56-c8308d800a83\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"75eb1f8f-5623-4ecf-a30e-6004ea8bcc90\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"f6ce3a8b-6859-4777-acdb-3cd4a8f0a17c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"66c0f136-0d9d-4564-b24e-200b5c979715\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"6833a697-e8b1-4796-be20-560843e24f39\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"cdeb006a-c876-4a22-ae90-b597507de8a6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"578fdd49-7dde-4a03-9db5-5fe24270dd87\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"fcb1fc65-6927-42cb-9db4-6458d1cd3c87\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"5a4b3cfc3c6ad5698a28167a316476fc\", element=\"72cd6bd2-3e72-4a7d-b75e-9b2e3b627009\")>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "locations_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e3c810c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru, Mumbai (All Areas)',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations_list=[]\n",
    "for i in locations_tags:\n",
    "    locations_list.append(i.text)\n",
    "locations_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b251197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(job1_titles[:10])),print(len(companies_names[:10])),print(len(locations_list[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "734cce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"C:\\Users\\arti\\Downloads\\chromedriver_win32\\chromedriver.exe\")\n",
    "driver.get('https://www.naukri.com/data-scientist-jobs-in-bangalore?k=data%20scientist&l=bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "611b1d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fe2eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1e5b179",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\"):\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a3c42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls[:10]:\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        description=driver.find_element_by_xpath(\"//section[@class='job-desc']\").text\n",
    "        job_description.append(description)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        job_description.append(\"Not Available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "807c745c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Job description\\nAbout upl:\\n\\nUPL is focused on emerging as a premier global provider of total crop solutions designed to secure the worlds long-term food supply. Winning farmers hearts across the globe, while leading the way with innovative products and services that make agriculture sustainable, UPL is the fastest growing company in the industry. UPL has a rich history of 50+ years with presence in 120+ countries. Based on the recognition that humankind is one community, UPLs overarching commitment is to improve areas of its presence, workplace, and customer engagement.\\n\\nOur purpose is OpenAg’. An Open agriculture network that feeds sustainable growth for all. No limits, no borders.\\n\\nIn order to create sustainable food chain, UPL is now working to build a future-ready, analytics-driven organization that will be even more efficient, more innovative, and more agile. We are setting up “Digital and Analytics” CoE to work on some disruptive projects that will have an impact that matters for the planet. It will help us reimagine our business to ensure the best outcomes for growers, consumers, employees, and our planet.\\nWork with us to get exposure to cutting-edge solutions in digital & advanced analytics, mentorship from senior leaders & domain experts, and access to a great work environment.\\n\\nJob Responsibilities:\\n\\nThe Senior Data Scientists will leverage expertise in advanced statistical and modelling techniques to design, prototype, and build the next-generation analytics engines and services. They will work closely with the analytics teams and business teams to derive actionable insights, helping the organization in achieving its’ strategic goals. Their work will involve high levels of interaction with the integrated analytics team, including data engineers, translators and more senior data scientists.\\n\\nHas expertise in implementing complex statistical analyses for data processing, exploration, model building and implementation\\nLead teams of 2-3 associate data scientists in the use case building and delivery process\\nIs able to communicate complex technical concepts to both technical and non technical audience\\nPlays a key role in driving ideation around the modeling process and developing models. Is able to conceptualize and drive re-iteration and fine tuning of models\\nContribute to knowledge building and sharing by researching best practices, documenting solutions and continuously iterating on new ways to solve problems. Mentors junior team members to do the same\\n\\nREQUIRED EDUCATION AND EXPERIENCE:\\n\\nMaster’s degree in Computer Science, Statistics, Math, Operations Research, Economics or a related field\\nAdvanced level programming skills in at least 1 coding language (R/Python/Scala)\\nPractical experience of developing advanced statistical and machine learning models\\nAt least 2 years of relevant analytics experience\\nExperience in using large database systems preferred\\nHas developed niche expertise in at least one functional domain\\n\\nRequired Skills :\\nAbility to work well in agile environments in diverse teams with multiple stakeholders\\nExperience of leading small teams\\nAble to problem solve complex problems and break them down into simpler parts\\nAbility to effectively communicate complex analytical and technical content\\nHigh energy and passionate individual who can work closely with other team members\\nStrong entrepreneurial drive to test new out of the box techniques\\nAble to prioritize workstreams and adopt an agile approach\\nWilling to adopt an iterative approach; experimental mindset to drive innovation\\n\\nLocation: Bangalore / Mumbai\\n\\nWhat’s in it for you?\\n\\nDisruptive projects: Work on ‘breakthrough’ digital-and-analytics projects to enable UPL’s vision of building a future ready organization. It involves deploying solutions to help us increase our sales, sustain our profitability, improve our speed to market, supercharge our R&D efforts, and support the way we work internally. Help us ensure we have access to the best business insights that our data analysis can offer us.\\n\\nCross functional leadership exposure: Work directly under guidance of functional leadership at UPL, on the most critical business problems for the organization (and the industry) today. It will give you exposure to a large cross-functional team (e.g.: spanning manufacturing, procurement, commercial, quality, IT/OT experts), allowing multi-functional learning in D&A deployment\\n\\nEnvironment fostering professional and personal development: Strengthen professional learning in a highly impact-oriented and meritocratic environment that is focused on delivering disproportionate business value through innovative solutions. It will be supported by on-the-job coaching from experienced domain experts, and continuous feedback from a highly motivated and capable set of peers. Comprehensive training programs for continuous development through UPL's D&A academy will help in accelerating growth opportunities.\\n\\nCome join us in this transformational journey!\\n\\nLet’s collectively Change the game with Digital & Analytics!\\nRoleData Science & Machine Learning - Other\\nIndustry TypeIT Services & Consulting\\nFunctional AreaData Science & Analytics\\nEmployment TypeFull Time, Permanent\\nRole CategoryData Science & Machine Learning\\nEducation\\nUG :Any Graduate\\nKey Skills\\npythonMLTstatistical modelingmachine learning\\nadvanced analyticsscalastatistics\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " 'Job description\\n  As a Senior Data Scientists for Walmart Labs, you ll have the opportunity to\\nPlay a key role to solve complex problems, pivotal to Walmart s business and drive actionable insights from terabytes of data\\nLeverage data science tools and techniques, keeping abreast with the latest in the community to solve problems for Walmart.\\nDevelop PoC, present lucidly to the business and evolve the solutions\\nTake forward the solutions into Pipelines/APIs as needed by the business\\nResearch, learn/disseminate adapt new technologies to solve problems improve upon existing solutions\\nBrainstorm, review and mentor junior associates in providing robust data science solutions\\nPosition Requirements:\\nMinimum qualifications:\\nMasters in Engineering/Technology or MSc with 4 years of relevant experience or PhD in AI\\nProblem solver at heart with experience in Machine learning and Data Science\\nProficiency with Python/PySpark/BiqQuery etc\\nProficiency with ML libraries sklearn/pytorch/tensorflow etc\\nGood knowledge of commonly used design patterns in data science\\nCloud friendliness (GCP/Azure etc) to leverage distributed computing/scalability\\nGood communication / influencing / mentoring skills with inclination to high ownership and commitment\\nRoleData warehouse Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaEngineering - Software & QA\\nEmployment TypeFull Time, Permanent\\nRole CategoryDBA / Data warehousing\\nEducation\\nUG :Any Graduate\\nPG :MS/M.Sc(Science) in Chemistry\\nKey Skills\\ndata scienceGCPAnalyticalMachine learningSupply chain operationsResearchbig dataForecastingAnalyticsPython',\n",
       " \"Job description\\nWHAT YOU'LL DO\\nWork along with the SAP CX Sales & Service Cloud development team in the following fields:\\nInvestigate AI/ML related technologies and their interaction with our ongoing product development in the CRM domain\\nSupport our existing cloud customer base to resolve their complex issues using ML\\nExperiment with AI/ML technologies in order to support CRM-centric predictive decision-making process implementation\\nFocus on software fault-tolerance to compensate for inevitable outages in the cloud\\nGuide our customers in their data driven application adoption journey\\nWork in rapid prototype and agile development environment\\nDevelop and put the ML models in production to serve multiple enterprise customers\\nPerform product design, modeling, implementation, and testing\\nClosely work with engineers, product Management, data scientists to translate customer requests into useful product functionality\\nWHAT YOU'LL BRING\\nRegular full time bachelor's or master's degree in engineering\\n5 - 10 years of relevant work experience\\nProficient in one or more programming languages (Python)\\nProficiency in ML technologies/libraries like scikit-learn, pytorch, spaCy, Gensim, BERT etc.\\nVery strong practical hand-on NLP technology usage knowhow (apply in business context)\\nStrong data exploration, cleansing, transformation, feature engineering skills\\nStrong SQL knowledge\\nStrong focus on delivering business values to customers\\nFamiliarity with TDD and tools like Git, GitHub, Jira etc.\\nFamiliarity with cloud computing and cloud native technologies (e.g. Docker, K8S etc.)\\nKnowledge in SAP technologies is a plus (SAP BTP, SAP HANA)\\nCRM functional domain knowledge is a plus\\nWillingness to interact with customers and passionate to solve their issues.\\nRoleData Scientist\\nIndustry TypeIT Services & Consulting\\nFunctional AreaData Science & Analytics\\nEmployment TypeFull Time, Permanent\\nRole CategoryData Science & Machine Learning\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :M.Tech in Any Specialization\\nKey Skills\\nPython\\nCloud computingNLPscikit-learnAgilepytorchdata explorationmachine learningAnalyticsSQL\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " \"Job description\\nAbout UPL:\\nUPL is focused on emerging as a premier global provider of total crop solutions designed to secure the worlds long-term food supply. Winning farmers hearts across the globe, while leading the way with innovative products and services that make agriculture sustainable, UPL is the fastest growing company in the industry. UPL has a rich history of 50+ years with presence in 120+ countries. Based on the recognition that humankind is one community, UPLs overarching commitment is to improve areas of its presence, workplace, and customer engagement.\\n\\nOur purpose is OpenAg. An Open agriculture network that feeds sustainable growth for all. No limits, no borders.\\n\\nIn order to create sustainable food chain, UPL is now working to build a future-ready, analytics-driven organization that will be even more efficient, more innovative, and more agile. We are setting up Digital and Analytics CoE to work on some disruptive projects that will have an impact that matters for the planet. It will help us reimagine our business to ensure the best outcomes for growers, consumers, employees, and our planet.\\nWork with us to get exposure to cutting-edge solutions in digital & advanced analytics, mentorship from senior leaders & domain experts, and access to a great work environment.\\n\\nJob Responsibilities:\\nThe Data Scientist will work as a core member of advanced analytics project delivery teams within the analytics Center of Excellence. This person will be responsible for conducting simple to complex statistical analyses using large datasets. They will be involved in building and re-iterating of advanced statistical and machine learning models. They will also work closely with an integrated analytics team including data engineers, translators and senior data scientists. They will be expected to familiarize themselves with a typical analytics project life cycle.\\n\\nConducts advanced statistical analysis to provide actionable insights, identify trends, and measure performance\\nCan build models using supervised/unsupervised learning techniques of varying complexity\\nUnderstanding of data engineering techniques and concepts like pilot testing and execution is a good to have\\nCollaborate with senior data scientists in building and delivering analytics models\\nCommunicate results to technical audience within an integrated analytics team\\nContribute to knowledge building and sharing by researching best practices, documenting solutions and continuously iterating on new ways to solve problems\\n\\n\\nREQUIRED EDUCATION AND EXPERIENCE:\\n\\nBachelor's degree in Computer Science, Statistics, Math, Operations Research, Economics or a related field.\\nBasic programming experience in 1 language\\nTheoretical knowledge of advanced analytics techniques\\nExperience in machine learning techniques preferred\\nHands on experience in solving analytics problems in at least 1 industry\\n\\nRequired Skills :\\nAbility to work well in agile environments in diverse teams with multiple stakeholders\\nStrong drive to learn and good organizational skills\\nAbility to effectively communicate complex analytical and technical content\\nHigh energy and passionate individual who can work closely with other team members\\nExcited about trying new solutions outside standard methodologies\\nWilling to adopt an iterative approach; experimental mindset to drive innovation\\n\\nLocation: Bangalore / Mumbai\\n\\nWhat's in it for you?\\n\\nDisruptive projects: Work on breakthrough digital-and-analytics projects to enable UPL’s vision of building a future ready organization. It involves deploying solutions to help us increase our sales, sustain our profitability, improve our speed to market, supercharge our R&D efforts, and support the way we work internally. Help us ensure we have access to the best business insights that our data analysis can offer us.\\n\\nCross functional leadership exposure: Work directly under guidance of functional leadership at UPL, on the most critical business problems for the organization (and the industry) today. It will give you exposure to a large cross-functional team (e.g.: spanning manufacturing, procurement, commercial, quality, IT/OT experts), allowing multi-functional learning in D&A deployment\\n\\nEnvironment fostering professional and personal development: Strengthen professional learning in a highly impact-oriented and meritocratic environment that is focused on delivering disproportionate business value through innovative solutions. It will be supported by on-the-job coaching from experienced domain experts, and continuous feedback from a highly motivated and capable set of peers. Comprehensive training programs for continuous development through UPL's D&A academy will help in accelerating growth opportunities.\\n\\n\\nCome join us in this transformational journey!\\n\\n\\nLet’s collectively Change the game with Digital & Analytics!\\n\\nRoleData Scientist\\nIndustry TypeIT Services & Consulting\\nFunctional AreaData Science & Analytics\\nEmployment TypeFull Time, Permanent\\nRole CategoryData Science & Machine Learning\\nEducation\\nUG :Any Graduate\\nKey Skills\\npythonmachine learning\\nData Sciencedata analysisawsazure\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " \"Job description\\nAbout upl:\\nUPL is focused on emerging as a premier global provider of total crop solutions designed to secure the worlds long-term food supply. Winning farmers hearts across the globe, while leading the way with innovative products and services that make agriculture sustainable, UPL is the fastest growing company in the industry. UPL has a rich history of 50+ years with presence in 120+ countries. Based on the recognition that humankind is one community, UPLs overarching commitment is to improve areas of its presence, workplace, and customer engagement.\\n\\nOur purpose is OpenAg’. An Open agriculture network that feeds sustainable growth for all. No limits, no borders.\\n\\nIn order to create sustainable food chain, UPL is now working to build a future-ready, analytics-driven organization that will be even more efficient, more innovative, and more agile. We are setting up “Digital and Analytics” CoE to work on some disruptive projects that will have an impact that matters for the planet. It will help us reimagine our business to ensure the best outcomes for growers, consumers, employees, and our planet.\\nWork with us to get exposure to cutting-edge solutions in digital & advanced analytics, mentorship from senior leaders & domain experts, and access to a great work environment.\\n\\nJob Responsibilities:\\nThe Principal Data Scientist will use both management experience and data science expertise to lead teams of data scientists across multiple analytics projects. This person will be an integral part of conceptualizing, scoping and delivering complex analytics projects. They will oversee the development, testing and maintenance of analytical models which mimic business decisions. This person will work closely with the leadership and business units in delivering impact through analytics. Additionally, this person will be responsible for continuously identifying opportunities to improve the ways of working and structuring within the analytics center of excellence.\\n\\nDefine and manage analytics strategy across multiple businesses\\nProvides analytical expertise in the process of model development, refining and implementation in a variety of analytics problems spread across a variety of domains\\nOversees large teams of associate and mid level data scientists, de-bottlenecking issues related to project execution\\nWork closely with translators and business teams to develop and implement analytics solutions\\nCollaborate with data engineers & architects to implement and deploy scalable solutions\\nCommunicate results to diverse technical and non technical audiences\\nActively drive a culture of knowledge building and sharing within the team. Encourage continuous innovation and out of the box thinking.\\nREQUIRED EDUCATION AND EXPERIENCE:\\nMaster’s degree in Computer Science, Statistics, Math, Operations Research, Economics or a related field\\nExperience in programming in at least 2 languages\\nSound theoretical and practical knowledge of working with advanced statistical algorithms, including machine learning techniques\\nAt least 10 years of experience of working in analytics\\nAt least 4 years of experience managing analytics teams. Experience in developing teams from\\nscratch a plus.\\nStrong business understanding. Worked in developing analytics solutions in 3-4 domains\\n\\nRequired Skills :\\nAbility to lead teams in agile environments, with multiple stakeholders involved\\nAbility to effectively communicate complex technical content to non-technical audience\\nSuccessful track record of structuring and leading complex analytics projects\\nProactive and passionate about resolving pain points through great design\\nSees value in iterative approach to model development\\nStrong sense of ownership and ability to build consensus\\nBelieves in culture of transparency and trust\\n\\nLocation: Bangalore / Mumbai\\n\\nWhat’s in it for you?\\nDisruptive projects: Work on ‘breakthrough’ digital-and-analytics projects to enable UPL’s vision of building a future ready organization. It involves deploying solutions to help us increase our sales, sustain our profitability, improve our speed to market, supercharge our R&D efforts, and support the way we work internally. Help us ensure we have access to the best business insights that our data analysis can offer us.\\n\\nCross functional leadership exposure: Work directly under guidance of functional leadership at UPL, on the most critical business problems for the organization (and the industry) today. It will give you exposure to a large cross-functional team (e.g.: spanning manufacturing, procurement, commercial, quality, IT/OT experts), allowing multi-functional learning in D&A deployment\\n\\nEnvironment fostering professional and personal development: Strengthen professional learning in a highly impact-oriented and meritocratic environment that is focused on delivering disproportionate business value through innovative solutions. It will be supported by on-the-job coaching from experienced domain experts, and continuous feedback from a highly motivated and capable set of peers. Comprehensive training programs for continuous development through UPL's D&A academy will help in accelerating growth opportunities.\\n\\nCome join us in this transformational journey!\\n\\n\\nLet’s collectively Change the game with Digital & Analytics!\\nRoleData Science & Machine Learning - Other\\nIndustry TypeIT Services & Consulting\\nFunctional AreaData Science & Analytics\\nEmployment TypeFull Time, Permanent\\nRole CategoryData Science & Machine Learning\\nEducation\\nUG :Any Graduate\\nKey Skills\\nTeam ManagementMLTmachine learningPython\\ndigital analyticsdata analysisdata scienceAWSstatistics\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " 'Job description\\n\\\\\\nAs a Data Scientist for Walmart Labs, you ll have the opportunity to\\nDrive data-derived insights across the wide range of retail divisions by developing advanced statistical models, machine learning algorithms and computational algorithms based on business initiatives\\nDirect the gathering of data, assessing data validity and synthesizing data into large analytics datasets to support project goals\\nUtilize big data analytics and advanced data science techniques to identify trends, patterns, and discrepancies in data. Determine additional data needed to support insights\\nBuild and train statistical models and machine learning algorithms for replication for future projects\\nCommunicate recommendations to business partners and influencing future plans based on insights\\nYour Responsibility:\\nVery good knowledge of the foundations of machine learning and statistics\\nExperience in analyzing the complex problems and translating them into data science problem\\nExperience in machine learning, supervised and unsupervised and deep learning.\\nHands on experience in Computer Visions and NLP.\\nExperience with big data analytics - identifying trends, patterns, and outliers in large volumes of data\\nStrong Experience in Python with excellent knowledge of Data Structures\\nStrong Experience with big data platforms - Hadoop (Hive, Pig, Map Reduce, HQL, Scala, Spark)\\nHands on experience with Git\\nExperience with SQL and relational databases, data warehouse\\nYour Qualifications:\\nBachelors with > 5 years of experience / Master s degree with > 3 years of experience. Educational qualifications should be preferably in Computer Science/Mathematics/Statistics or a related area. Experience should be relevant to the role\\nMust have:\\nGood knowledge of Probability and Statistics, Linear Algebra, Convex Optimization, Algorithms\\nGood knowledge of Machine Learning fundamentals (Supervised learning, Unsupervised learning, Regression, Classification, Clustering, Maximum Likelihood Estimation, Regularization, ...)\\nGood knowledge of ML models like Logistic Regression, SVMs, Random Forests, Gaussian Mixture Models among others\\nGood knowledge of Deep Learning models and fundamentals like CNN, LSTM and Sequence Models, Word Embeddings (Word2Vec or Glove, BERT,...)\\nGood knowledge of a Deep Learning framework- Tensorflow or PyTorch\\nGood knowledge of Python including numpy, sklearn, pandas\\nA very strong problem-solving mindset, with eagerness to learn (and this can compensate for weakness in any of the above points)\\nRoleTechnical Lead\\nIndustry TypeIT Services & Consulting\\nFunctional AreaEngineering - Software & QA\\nEmployment TypeFull Time, Permanent\\nRole CategorySoftware Development\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nComputer scienceComputer visiondeep learningData analysisArtificial IntelligenceMachine learningData structuresNatural language processingSQLPython',\n",
       " 'Job description\\n  Understand the data sources in Walmart.\\nSample-extract-clean-transform data, detect outliers. Simply build efficient feature extraction, training and prediction pipelines.\\nDevelop machine learning models for the business use cases in Walmart. This will include various ML models spanning both supervised and unsupervised learning.\\nDesigning and developing MLOps for machine learning and deep learning systems.\\nWrite functions for statistical analysis of data.\\nBuild compelling data visualisations and interactive dashboards for monitoring and sharing of business KPIs and data insights.\\nConvert developed models to deployable artefacts.\\nConduct experiments to improve deployed models.\\nProvide innovative solutions to the business problems, and drive patents and publications on this work, popularise the work by demonstrations and blogs.\\nRead and replicate latest research with an eye towards applying it to problems in Walmart\\nWork in an agile environment to deliver high quality solutions, with globally distributed and remote teams\\nPromote and support company policies, procedures, mission and uphold the values and standards of ethics and integrity\\nOur ideal candidate is an energetic, self-motivated individual, excited by AL/ML and focused on solving customer problems. She/he is a quick learner, out-of-the-box thinker and a good problem solver. She/he is someone who thrives in a fun, fast-paced, and dynamic environment.\\nPosition Requirements:\\nMinimum qualifications:\\nShould have strong computer science fundamentals in data structures and algorithms, object oriented programming\\nKnowledge of the foundations of machine learning and statistics\\nA continuous drive to explore, improve, enhance, automate and optimise systems and tools.\\nExposure to cloud infrastructure, such as Azure, GCP.\\nExperience in building of large scale data pipelines using big data technologies (i. e. Spark / Kafka / Hadoop / Hive / Airflow)\\nStrong software development skills in languages such as Python or Scala.\\nExposure to open source ML frameworks like scikit learn, keras, SparkML lib, etc.\\nExperience in building of large scale data pipelines using big data technologies (i.e. Spark / Kafka / Cassandra / Hadoop / Hive / Presto / Airflow).\\nExperience in systems design, algorithms, and distributed systems.\\nRoleTechnical Lead\\nIndustry TypeIT Services & Consulting\\nFunctional AreaEngineering - Software & QA\\nEmployment TypeFull Time, Permanent\\nRole CategorySoftware Development\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nComputer sciencecassandraMachine learningAgileData structuresOpen sourceDistribution systemAnalyticsMonitoringPython',\n",
       " \"Job description\\nAbout UPL:\\nUPL is focused on emerging as a premier global provider of total crop solutions designed to secure the worlds long-term food supply. Winning farmers hearts across the globe, while leading the way with innovative products and services that make agriculture sustainable, UPL is the fastest growing company in the industry. UPL has a rich history of 50+ years with presence in 120+ countries. Based on the recognition that humankind is one community, UPL’s overarching commitment is to improve areas of its presence, workplace, and customer engagement.\\n\\nOur purpose is ‘OpenAg’. An Open agriculture network that feeds sustainable growth for all. No limits, no borders.\\n\\nIn order to create sustainable food chain, UPL is now working to build a future-ready, analytics-driven organization that will be even more efficient, more innovative, and more agile. We are setting up “Digital and Analytics” CoE to work on some disruptive projects that will have an impact that matters for the planet. It will help us reimagine our business to ensure the best outcomes for growers, consumers, employees, and our planet.\\nWork with us to get exposure to cutting-edge solutions in digital & advanced analytics, mentorship from senior leaders & domain experts, and access to a great work environment.\\n\\nJob Responsibilities:\\n\\nThe Expert Data Scientist will use both management experience and data science expertise to lead teams of data scientists across multiple analytics projects. This person will be an integral part of conceptualizing, scoping and delivering complex analytics projects. They will oversee the development, testing and maintenance of analytical models which mimic business decisions. This person will work closely with the CoE leadership and business units in delivering impact through analytics. Additionally, this person will be responsible for continuously identifying opportunities to improve the ways of working and structuring within the analytics center of excellence.\\nManage analytics strategy across multiple use cases\\nProvides analytical expertise in the process of model development, refining and implementation in a variety of analytics problems spread across a variety of domains\\nOversees large teams of associate and mid level data scientists, de-bottlenecking issues related to project execution\\nWork closely with translators and business teams to develop and implement analytics solutions\\nCollaborate with data engineers & architects to implement and deploy scalable solutions\\nCommunicate results to diverse technical and non technical audiences\\nActively drive a culture of knowledge building and sharing within the team. Encourage continuous innovation and out of the box thinking.\\n\\nREQUIRED EDUCATION AND EXPERIENCE:\\nMaster’s degree in Computer Science, Statistics, Math, Operations Research, Economics or a related field\\nExperience in programming in at least 2 languages\\nSound theoretical and practical knowledge of working with advanced statistical algorithms, including machine learning techniques\\nAt least 6 years of experience of working in analytics and leading teams\\nWorked in developing analytics solutions in 3-4 domains\\n\\nRequired Skills :\\nAbility to lead teams in agile environments, with multiple stakeholders involved\\nAbility to effectively communicate complex technical content to non-technical audience\\nSuccessful track record of structuring and leading complex analytics projects\\nProactive and passionate about resolving pain points through great design\\nSees value in iterative approach to model development\\nStrong sense of ownership and ability to build consensus\\nBelieves in culture of transparency and trust\\n\\nLocation: Bangalore / Mumbai\\n\\nWhat’s in it for you?\\n\\nDisruptive projects: Work on ‘breakthrough’ digital-and-analytics projects to enable UPL’s vision of building a future ready organization. It involves deploying solutions to help us increase our sales, sustain our profitability, improve our speed to market, supercharge our R&D efforts, and support the way we work internally. Help us ensure we have access to the best business insights that our data analysis can offer us.\\n\\nCross functional leadership exposure: Work directly under guidance of functional leadership at UPL, on the most critical business problems for the organization (and the industry) today. It will give you exposure to a large cross-functional team (e.g.: spanning manufacturing, procurement, commercial, quality, IT/OT experts), allowing multi-functional learning in D&A deployment\\n\\nEnvironment fostering professional and personal development: Strengthen professional learning in a highly impact-oriented and meritocratic environment that is focused on delivering disproportionate business value through innovative solutions. It will be supported by on-the-job coaching from experienced domain experts, and continuous feedback from a highly motivated and capable set of peers. Comprehensive training programs for continuous development through UPL's D&A academy will help in accelerating growth opportunities.\\n\\nCome join us in this transformational journey!\\n\\nLet’s collectively Change the game with Digital & Analytics!\\nRoleData Science & Machine Learning - Other\\nIndustry TypeIT Services & Consulting\\nFunctional AreaData Science & Analytics\\nEmployment TypeFull Time, Permanent\\nRole CategoryData Science & Machine Learning\\nEducation\\nUG :Any Graduate\\nKey Skills\\nteam leadMLTmachine learningawsPython\\ndata scienceazurestatistics\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " \"Job description\\nAbout upl:\\n\\nUPL is focused on emerging as a premier global provider of total crop solutions designed to secure the worlds long-term food supply. Winning farmers hearts across the globe, while leading the way with innovative products and services that make agriculture sustainable, UPL is the fastest growing company in the industry. UPL has a rich history of 50+ years with presence in 120+ countries. Based on the recognition that humankind is one community, UPLs overarching commitment is to improve areas of its presence, workplace, and customer engagement.\\n\\nOur purpose is OpenAg’. An Open agriculture network that feeds sustainable growth for all. No limits, no borders.\\n\\nIn order to create sustainable food chain, UPL is now working to build a future-ready, analytics-driven organization that will be even more efficient, more innovative, and more agile. We are setting up “Digital and Analytics” CoE to work on some disruptive projects that will have an impact that matters for the planet. It will help us reimagine our business to ensure the best outcomes for growers, consumers, employees, and our planet.\\nWork with us to get exposure to cutting-edge solutions in digital & advanced analytics, mentorship from senior leaders & domain experts, and access to a great work environment.\\n\\nJob Responsibilities:\\n\\nThe Senior Data Scientists will leverage expertise in advanced statistical and modelling techniques to design, prototype, and build the next-generation analytics engines and services. They will work closely with the analytics teams and business teams to derive actionable insights, helping the organization in achieving its’ strategic goals. Their work will involve high levels of interaction with the integrated analytics team, including data engineers, translators and more senior data scientists.\\n\\nHas expertise in implementing complex statistical analyses for data processing, exploration, model building and implementation\\nLead teams of 2-3 associate data scientists in the use case building and delivery process\\nIs able to communicate complex technical concepts to both technical and non technical audience\\nPlays a key role in driving ideation around the modeling process and developing models. Is able to conceptualize and drive re-iteration and fine tuning of models\\nContribute to knowledge building and sharing by researching best practices, documenting solutions and continuously iterating on new ways to solve problems. Mentors junior team members to do the same\\n\\nREQUIRED EDUCATION AND EXPERIENCE:\\n\\nMaster’s degree in Computer Science, Statistics, Math, Operations Research, Economics or a related field\\nAdvanced level programming skills in at least 1 coding language (R/Python/Scala)\\nPractical experience of developing advanced statistical and machine learning models\\nAt least 2 years of relevant analytics experience\\nExperience in using large database systems preferred\\nHas developed niche expertise in at least one functional domain\\n\\nRequired Skills :\\nAbility to work well in agile environments in diverse teams with multiple stakeholders\\nExperience of leading small teams\\nAble to problem solve complex problems and break them down into simpler parts\\nAbility to effectively communicate complex analytical and technical content\\nHigh energy and passionate individual who can work closely with other team members\\nStrong entrepreneurial drive to test new out of the box techniques\\nAble to prioritize workstreams and adopt an agile approach\\nWilling to adopt an iterative approach; experimental mindset to drive innovation\\n\\nLocation: Bangalore / Mumbai\\n\\nWhat’s in it for you?\\n\\nDisruptive projects: Work on ‘breakthrough’ digital-and-analytics projects to enable UPL’s vision of building a future ready organization. It involves deploying solutions to help us increase our sales, sustain our profitability, improve our speed to market, supercharge our R&D efforts, and support the way we work internally. Help us ensure we have access to the best business insights that our data analysis can offer us.\\n\\nCross functional leadership exposure: Work directly under guidance of functional leadership at UPL, on the most critical business problems for the organization (and the industry) today. It will give you exposure to a large cross-functional team (e.g.: spanning manufacturing, procurement, commercial, quality, IT/OT experts), allowing multi-functional learning in D&A deployment\\n\\nEnvironment fostering professional and personal development: Strengthen professional learning in a highly impact-oriented and meritocratic environment that is focused on delivering disproportionate business value through innovative solutions. It will be supported by on-the-job coaching from experienced domain experts, and continuous feedback from a highly motivated and capable set of peers. Comprehensive training programs for continuous development through UPL's D&A academy will help in accelerating growth opportunities.\\n\\nCome join us in this transformational journey!\\n\\nLet’s collectively Change the game with Digital & Analytics!\\nRoleData Science & Machine Learning - Other\\nIndustry TypeIT Services & Consulting\\nFunctional AreaData Science & Analytics\\nEmployment TypeFull Time, Permanent\\nRole CategoryData Science & Machine Learning\\nEducation\\nUG :Any Graduate\\nKey Skills\\npythonMLTstatistical modelingmachine learning\\nadvanced analyticsscalastatistics\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " 'Job description\\n  As a Senior Data Scientists for Walmart Labs, you ll have the opportunity to\\nPlay a key role to solve complex problems, pivotal to Walmart s business and drive actionable insights from terabytes of data\\nLeverage data science tools and techniques, keeping abreast with the latest in the community to solve problems for Walmart.\\nDevelop PoC, present lucidly to the business and evolve the solutions\\nTake forward the solutions into Pipelines/APIs as needed by the business\\nResearch, learn/disseminate adapt new technologies to solve problems improve upon existing solutions\\nBrainstorm, review and mentor junior associates in providing robust data science solutions\\nPosition Requirements:\\nMinimum qualifications:\\nMasters in Engineering/Technology or MSc with 4 years of relevant experience or PhD in AI\\nProblem solver at heart with experience in Machine learning and Data Science\\nProficiency with Python/PySpark/BiqQuery etc\\nProficiency with ML libraries sklearn/pytorch/tensorflow etc\\nGood knowledge of commonly used design patterns in data science\\nCloud friendliness (GCP/Azure etc) to leverage distributed computing/scalability\\nGood communication / influencing / mentoring skills with inclination to high ownership and commitment\\nRoleData warehouse Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaEngineering - Software & QA\\nEmployment TypeFull Time, Permanent\\nRole CategoryDBA / Data warehousing\\nEducation\\nUG :Any Graduate\\nPG :MS/M.Sc(Science) in Chemistry\\nKey Skills\\ndata scienceGCPAnalyticalMachine learningSupply chain operationsResearchbig dataForecastingAnalyticsPython',\n",
       " \"Job description\\nWHAT YOU'LL DO\\nWork along with the SAP CX Sales & Service Cloud development team in the following fields:\\nInvestigate AI/ML related technologies and their interaction with our ongoing product development in the CRM domain\\nSupport our existing cloud customer base to resolve their complex issues using ML\\nExperiment with AI/ML technologies in order to support CRM-centric predictive decision-making process implementation\\nFocus on software fault-tolerance to compensate for inevitable outages in the cloud\\nGuide our customers in their data driven application adoption journey\\nWork in rapid prototype and agile development environment\\nDevelop and put the ML models in production to serve multiple enterprise customers\\nPerform product design, modeling, implementation, and testing\\nClosely work with engineers, product Management, data scientists to translate customer requests into useful product functionality\\nWHAT YOU'LL BRING\\nRegular full time bachelor's or master's degree in engineering\\n5 - 10 years of relevant work experience\\nProficient in one or more programming languages (Python)\\nProficiency in ML technologies/libraries like scikit-learn, pytorch, spaCy, Gensim, BERT etc.\\nVery strong practical hand-on NLP technology usage knowhow (apply in business context)\\nStrong data exploration, cleansing, transformation, feature engineering skills\\nStrong SQL knowledge\\nStrong focus on delivering business values to customers\\nFamiliarity with TDD and tools like Git, GitHub, Jira etc.\\nFamiliarity with cloud computing and cloud native technologies (e.g. Docker, K8S etc.)\\nKnowledge in SAP technologies is a plus (SAP BTP, SAP HANA)\\nCRM functional domain knowledge is a plus\\nWillingness to interact with customers and passionate to solve their issues.\\nRoleData Scientist\\nIndustry TypeIT Services & Consulting\\nFunctional AreaData Science & Analytics\\nEmployment TypeFull Time, Permanent\\nRole CategoryData Science & Machine Learning\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :M.Tech in Any Specialization\\nKey Skills\\nPython\\nCloud computingNLPscikit-learnAgilepytorchdata explorationmachine learningAnalyticsSQL\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " \"Job description\\nAbout UPL:\\nUPL is focused on emerging as a premier global provider of total crop solutions designed to secure the worlds long-term food supply. Winning farmers hearts across the globe, while leading the way with innovative products and services that make agriculture sustainable, UPL is the fastest growing company in the industry. UPL has a rich history of 50+ years with presence in 120+ countries. Based on the recognition that humankind is one community, UPLs overarching commitment is to improve areas of its presence, workplace, and customer engagement.\\n\\nOur purpose is OpenAg. An Open agriculture network that feeds sustainable growth for all. No limits, no borders.\\n\\nIn order to create sustainable food chain, UPL is now working to build a future-ready, analytics-driven organization that will be even more efficient, more innovative, and more agile. We are setting up Digital and Analytics CoE to work on some disruptive projects that will have an impact that matters for the planet. It will help us reimagine our business to ensure the best outcomes for growers, consumers, employees, and our planet.\\nWork with us to get exposure to cutting-edge solutions in digital & advanced analytics, mentorship from senior leaders & domain experts, and access to a great work environment.\\n\\nJob Responsibilities:\\nThe Data Scientist will work as a core member of advanced analytics project delivery teams within the analytics Center of Excellence. This person will be responsible for conducting simple to complex statistical analyses using large datasets. They will be involved in building and re-iterating of advanced statistical and machine learning models. They will also work closely with an integrated analytics team including data engineers, translators and senior data scientists. They will be expected to familiarize themselves with a typical analytics project life cycle.\\n\\nConducts advanced statistical analysis to provide actionable insights, identify trends, and measure performance\\nCan build models using supervised/unsupervised learning techniques of varying complexity\\nUnderstanding of data engineering techniques and concepts like pilot testing and execution is a good to have\\nCollaborate with senior data scientists in building and delivering analytics models\\nCommunicate results to technical audience within an integrated analytics team\\nContribute to knowledge building and sharing by researching best practices, documenting solutions and continuously iterating on new ways to solve problems\\n\\n\\nREQUIRED EDUCATION AND EXPERIENCE:\\n\\nBachelor's degree in Computer Science, Statistics, Math, Operations Research, Economics or a related field.\\nBasic programming experience in 1 language\\nTheoretical knowledge of advanced analytics techniques\\nExperience in machine learning techniques preferred\\nHands on experience in solving analytics problems in at least 1 industry\\n\\nRequired Skills :\\nAbility to work well in agile environments in diverse teams with multiple stakeholders\\nStrong drive to learn and good organizational skills\\nAbility to effectively communicate complex analytical and technical content\\nHigh energy and passionate individual who can work closely with other team members\\nExcited about trying new solutions outside standard methodologies\\nWilling to adopt an iterative approach; experimental mindset to drive innovation\\n\\nLocation: Bangalore / Mumbai\\n\\nWhat's in it for you?\\n\\nDisruptive projects: Work on breakthrough digital-and-analytics projects to enable UPL’s vision of building a future ready organization. It involves deploying solutions to help us increase our sales, sustain our profitability, improve our speed to market, supercharge our R&D efforts, and support the way we work internally. Help us ensure we have access to the best business insights that our data analysis can offer us.\\n\\nCross functional leadership exposure: Work directly under guidance of functional leadership at UPL, on the most critical business problems for the organization (and the industry) today. It will give you exposure to a large cross-functional team (e.g.: spanning manufacturing, procurement, commercial, quality, IT/OT experts), allowing multi-functional learning in D&A deployment\\n\\nEnvironment fostering professional and personal development: Strengthen professional learning in a highly impact-oriented and meritocratic environment that is focused on delivering disproportionate business value through innovative solutions. It will be supported by on-the-job coaching from experienced domain experts, and continuous feedback from a highly motivated and capable set of peers. Comprehensive training programs for continuous development through UPL's D&A academy will help in accelerating growth opportunities.\\n\\n\\nCome join us in this transformational journey!\\n\\n\\nLet’s collectively Change the game with Digital & Analytics!\\n\\nRoleData Scientist\\nIndustry TypeIT Services & Consulting\\nFunctional AreaData Science & Analytics\\nEmployment TypeFull Time, Permanent\\nRole CategoryData Science & Machine Learning\\nEducation\\nUG :Any Graduate\\nKey Skills\\npythonmachine learning\\nData Sciencedata analysisawsazure\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " \"Job description\\nAbout upl:\\n\\nUPL is focused on emerging as a premier global provider of total crop solutions designed to secure the worlds long-term food supply. Winning farmers hearts across the globe, while leading the way with innovative products and services that make agriculture sustainable, UPL is the fastest growing company in the industry. UPL has a rich history of 50+ years with presence in 120+ countries. Based on the recognition that humankind is one community, UPLs overarching commitment is to improve areas of its presence, workplace, and customer engagement.\\n\\nOur purpose is OpenAg’. An Open agriculture network that feeds sustainable growth for all. No limits, no borders.\\n\\nIn order to create sustainable food chain, UPL is now working to build a future-ready, analytics-driven organization that will be even more efficient, more innovative, and more agile. We are setting up “Digital and Analytics” CoE to work on some disruptive projects that will have an impact that matters for the planet. It will help us reimagine our business to ensure the best outcomes for growers, consumers, employees, and our planet.\\nWork with us to get exposure to cutting-edge solutions in digital & advanced analytics, mentorship from senior leaders & domain experts, and access to a great work environment.\\n\\nJob Responsibilities:\\n\\nThe Senior Data Scientists will leverage expertise in advanced statistical and modelling techniques to design, prototype, and build the next-generation analytics engines and services. They will work closely with the analytics teams and business teams to derive actionable insights, helping the organization in achieving its’ strategic goals. Their work will involve high levels of interaction with the integrated analytics team, including data engineers, translators and more senior data scientists.\\n\\nHas expertise in implementing complex statistical analyses for data processing, exploration, model building and implementation\\nLead teams of 2-3 associate data scientists in the use case building and delivery process\\nIs able to communicate complex technical concepts to both technical and non technical audience\\nPlays a key role in driving ideation around the modeling process and developing models. Is able to conceptualize and drive re-iteration and fine tuning of models\\nContribute to knowledge building and sharing by researching best practices, documenting solutions and continuously iterating on new ways to solve problems. Mentors junior team members to do the same\\n\\nREQUIRED EDUCATION AND EXPERIENCE:\\n\\nMaster’s degree in Computer Science, Statistics, Math, Operations Research, Economics or a related field\\nAdvanced level programming skills in at least 1 coding language (R/Python/Scala)\\nPractical experience of developing advanced statistical and machine learning models\\nAt least 2 years of relevant analytics experience\\nExperience in using large database systems preferred\\nHas developed niche expertise in at least one functional domain\\n\\nRequired Skills :\\nAbility to work well in agile environments in diverse teams with multiple stakeholders\\nExperience of leading small teams\\nAble to problem solve complex problems and break them down into simpler parts\\nAbility to effectively communicate complex analytical and technical content\\nHigh energy and passionate individual who can work closely with other team members\\nStrong entrepreneurial drive to test new out of the box techniques\\nAble to prioritize workstreams and adopt an agile approach\\nWilling to adopt an iterative approach; experimental mindset to drive innovation\\n\\nLocation: Bangalore / Mumbai\\n\\nWhat’s in it for you?\\n\\nDisruptive projects: Work on ‘breakthrough’ digital-and-analytics projects to enable UPL’s vision of building a future ready organization. It involves deploying solutions to help us increase our sales, sustain our profitability, improve our speed to market, supercharge our R&D efforts, and support the way we work internally. Help us ensure we have access to the best business insights that our data analysis can offer us.\\n\\nCross functional leadership exposure: Work directly under guidance of functional leadership at UPL, on the most critical business problems for the organization (and the industry) today. It will give you exposure to a large cross-functional team (e.g.: spanning manufacturing, procurement, commercial, quality, IT/OT experts), allowing multi-functional learning in D&A deployment\\n\\nEnvironment fostering professional and personal development: Strengthen professional learning in a highly impact-oriented and meritocratic environment that is focused on delivering disproportionate business value through innovative solutions. It will be supported by on-the-job coaching from experienced domain experts, and continuous feedback from a highly motivated and capable set of peers. Comprehensive training programs for continuous development through UPL's D&A academy will help in accelerating growth opportunities.\\n\\nCome join us in this transformational journey!\\n\\nLet’s collectively Change the game with Digital & Analytics!\\nRoleData Science & Machine Learning - Other\\nIndustry TypeIT Services & Consulting\\nFunctional AreaData Science & Analytics\\nEmployment TypeFull Time, Permanent\\nRole CategoryData Science & Machine Learning\\nEducation\\nUG :Any Graduate\\nKey Skills\\npythonMLTstatistical modelingmachine learning\\nadvanced analyticsscalastatistics\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " 'Job description\\n  As a Senior Data Scientists for Walmart Labs, you ll have the opportunity to\\nPlay a key role to solve complex problems, pivotal to Walmart s business and drive actionable insights from terabytes of data\\nLeverage data science tools and techniques, keeping abreast with the latest in the community to solve problems for Walmart.\\nDevelop PoC, present lucidly to the business and evolve the solutions\\nTake forward the solutions into Pipelines/APIs as needed by the business\\nResearch, learn/disseminate adapt new technologies to solve problems improve upon existing solutions\\nBrainstorm, review and mentor junior associates in providing robust data science solutions\\nPosition Requirements:\\nMinimum qualifications:\\nMasters in Engineering/Technology or MSc with 4 years of relevant experience or PhD in AI\\nProblem solver at heart with experience in Machine learning and Data Science\\nProficiency with Python/PySpark/BiqQuery etc\\nProficiency with ML libraries sklearn/pytorch/tensorflow etc\\nGood knowledge of commonly used design patterns in data science\\nCloud friendliness (GCP/Azure etc) to leverage distributed computing/scalability\\nGood communication / influencing / mentoring skills with inclination to high ownership and commitment\\nRoleData warehouse Developer\\nIndustry TypeIT Services & Consulting\\nFunctional AreaEngineering - Software & QA\\nEmployment TypeFull Time, Permanent\\nRole CategoryDBA / Data warehousing\\nEducation\\nUG :Any Graduate\\nPG :MS/M.Sc(Science) in Chemistry\\nKey Skills\\ndata scienceGCPAnalyticalMachine learningSupply chain operationsResearchbig dataForecastingAnalyticsPython',\n",
       " \"Job description\\nWHAT YOU'LL DO\\nWork along with the SAP CX Sales & Service Cloud development team in the following fields:\\nInvestigate AI/ML related technologies and their interaction with our ongoing product development in the CRM domain\\nSupport our existing cloud customer base to resolve their complex issues using ML\\nExperiment with AI/ML technologies in order to support CRM-centric predictive decision-making process implementation\\nFocus on software fault-tolerance to compensate for inevitable outages in the cloud\\nGuide our customers in their data driven application adoption journey\\nWork in rapid prototype and agile development environment\\nDevelop and put the ML models in production to serve multiple enterprise customers\\nPerform product design, modeling, implementation, and testing\\nClosely work with engineers, product Management, data scientists to translate customer requests into useful product functionality\\nWHAT YOU'LL BRING\\nRegular full time bachelor's or master's degree in engineering\\n5 - 10 years of relevant work experience\\nProficient in one or more programming languages (Python)\\nProficiency in ML technologies/libraries like scikit-learn, pytorch, spaCy, Gensim, BERT etc.\\nVery strong practical hand-on NLP technology usage knowhow (apply in business context)\\nStrong data exploration, cleansing, transformation, feature engineering skills\\nStrong SQL knowledge\\nStrong focus on delivering business values to customers\\nFamiliarity with TDD and tools like Git, GitHub, Jira etc.\\nFamiliarity with cloud computing and cloud native technologies (e.g. Docker, K8S etc.)\\nKnowledge in SAP technologies is a plus (SAP BTP, SAP HANA)\\nCRM functional domain knowledge is a plus\\nWillingness to interact with customers and passionate to solve their issues.\\nRoleData Scientist\\nIndustry TypeIT Services & Consulting\\nFunctional AreaData Science & Analytics\\nEmployment TypeFull Time, Permanent\\nRole CategoryData Science & Machine Learning\\nEducation\\nUG :B.Tech/B.E. in Any Specialization\\nPG :M.Tech in Any Specialization\\nKey Skills\\nPython\\nCloud computingNLPscikit-learnAgilepytorchdata explorationmachine learningAnalyticsSQL\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " \"Job description\\nAbout UPL:\\nUPL is focused on emerging as a premier global provider of total crop solutions designed to secure the worlds long-term food supply. Winning farmers hearts across the globe, while leading the way with innovative products and services that make agriculture sustainable, UPL is the fastest growing company in the industry. UPL has a rich history of 50+ years with presence in 120+ countries. Based on the recognition that humankind is one community, UPLs overarching commitment is to improve areas of its presence, workplace, and customer engagement.\\n\\nOur purpose is OpenAg. An Open agriculture network that feeds sustainable growth for all. No limits, no borders.\\n\\nIn order to create sustainable food chain, UPL is now working to build a future-ready, analytics-driven organization that will be even more efficient, more innovative, and more agile. We are setting up Digital and Analytics CoE to work on some disruptive projects that will have an impact that matters for the planet. It will help us reimagine our business to ensure the best outcomes for growers, consumers, employees, and our planet.\\nWork with us to get exposure to cutting-edge solutions in digital & advanced analytics, mentorship from senior leaders & domain experts, and access to a great work environment.\\n\\nJob Responsibilities:\\nThe Data Scientist will work as a core member of advanced analytics project delivery teams within the analytics Center of Excellence. This person will be responsible for conducting simple to complex statistical analyses using large datasets. They will be involved in building and re-iterating of advanced statistical and machine learning models. They will also work closely with an integrated analytics team including data engineers, translators and senior data scientists. They will be expected to familiarize themselves with a typical analytics project life cycle.\\n\\nConducts advanced statistical analysis to provide actionable insights, identify trends, and measure performance\\nCan build models using supervised/unsupervised learning techniques of varying complexity\\nUnderstanding of data engineering techniques and concepts like pilot testing and execution is a good to have\\nCollaborate with senior data scientists in building and delivering analytics models\\nCommunicate results to technical audience within an integrated analytics team\\nContribute to knowledge building and sharing by researching best practices, documenting solutions and continuously iterating on new ways to solve problems\\n\\n\\nREQUIRED EDUCATION AND EXPERIENCE:\\n\\nBachelor's degree in Computer Science, Statistics, Math, Operations Research, Economics or a related field.\\nBasic programming experience in 1 language\\nTheoretical knowledge of advanced analytics techniques\\nExperience in machine learning techniques preferred\\nHands on experience in solving analytics problems in at least 1 industry\\n\\nRequired Skills :\\nAbility to work well in agile environments in diverse teams with multiple stakeholders\\nStrong drive to learn and good organizational skills\\nAbility to effectively communicate complex analytical and technical content\\nHigh energy and passionate individual who can work closely with other team members\\nExcited about trying new solutions outside standard methodologies\\nWilling to adopt an iterative approach; experimental mindset to drive innovation\\n\\nLocation: Bangalore / Mumbai\\n\\nWhat's in it for you?\\n\\nDisruptive projects: Work on breakthrough digital-and-analytics projects to enable UPL’s vision of building a future ready organization. It involves deploying solutions to help us increase our sales, sustain our profitability, improve our speed to market, supercharge our R&D efforts, and support the way we work internally. Help us ensure we have access to the best business insights that our data analysis can offer us.\\n\\nCross functional leadership exposure: Work directly under guidance of functional leadership at UPL, on the most critical business problems for the organization (and the industry) today. It will give you exposure to a large cross-functional team (e.g.: spanning manufacturing, procurement, commercial, quality, IT/OT experts), allowing multi-functional learning in D&A deployment\\n\\nEnvironment fostering professional and personal development: Strengthen professional learning in a highly impact-oriented and meritocratic environment that is focused on delivering disproportionate business value through innovative solutions. It will be supported by on-the-job coaching from experienced domain experts, and continuous feedback from a highly motivated and capable set of peers. Comprehensive training programs for continuous development through UPL's D&A academy will help in accelerating growth opportunities.\\n\\n\\nCome join us in this transformational journey!\\n\\n\\nLet’s collectively Change the game with Digital & Analytics!\\n\\nRoleData Scientist\\nIndustry TypeIT Services & Consulting\\nFunctional AreaData Science & Analytics\\nEmployment TypeFull Time, Permanent\\nRole CategoryData Science & Machine Learning\\nEducation\\nUG :Any Graduate\\nKey Skills\\npythonmachine learning\\nData Sciencedata analysisawsazure\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " \"Job description\\nAbout upl:\\nUPL is focused on emerging as a premier global provider of total crop solutions designed to secure the worlds long-term food supply. Winning farmers hearts across the globe, while leading the way with innovative products and services that make agriculture sustainable, UPL is the fastest growing company in the industry. UPL has a rich history of 50+ years with presence in 120+ countries. Based on the recognition that humankind is one community, UPLs overarching commitment is to improve areas of its presence, workplace, and customer engagement.\\n\\nOur purpose is OpenAg’. An Open agriculture network that feeds sustainable growth for all. No limits, no borders.\\n\\nIn order to create sustainable food chain, UPL is now working to build a future-ready, analytics-driven organization that will be even more efficient, more innovative, and more agile. We are setting up “Digital and Analytics” CoE to work on some disruptive projects that will have an impact that matters for the planet. It will help us reimagine our business to ensure the best outcomes for growers, consumers, employees, and our planet.\\nWork with us to get exposure to cutting-edge solutions in digital & advanced analytics, mentorship from senior leaders & domain experts, and access to a great work environment.\\n\\nJob Responsibilities:\\nThe Principal Data Scientist will use both management experience and data science expertise to lead teams of data scientists across multiple analytics projects. This person will be an integral part of conceptualizing, scoping and delivering complex analytics projects. They will oversee the development, testing and maintenance of analytical models which mimic business decisions. This person will work closely with the leadership and business units in delivering impact through analytics. Additionally, this person will be responsible for continuously identifying opportunities to improve the ways of working and structuring within the analytics center of excellence.\\n\\nDefine and manage analytics strategy across multiple businesses\\nProvides analytical expertise in the process of model development, refining and implementation in a variety of analytics problems spread across a variety of domains\\nOversees large teams of associate and mid level data scientists, de-bottlenecking issues related to project execution\\nWork closely with translators and business teams to develop and implement analytics solutions\\nCollaborate with data engineers & architects to implement and deploy scalable solutions\\nCommunicate results to diverse technical and non technical audiences\\nActively drive a culture of knowledge building and sharing within the team. Encourage continuous innovation and out of the box thinking.\\nREQUIRED EDUCATION AND EXPERIENCE:\\nMaster’s degree in Computer Science, Statistics, Math, Operations Research, Economics or a related field\\nExperience in programming in at least 2 languages\\nSound theoretical and practical knowledge of working with advanced statistical algorithms, including machine learning techniques\\nAt least 10 years of experience of working in analytics\\nAt least 4 years of experience managing analytics teams. Experience in developing teams from\\nscratch a plus.\\nStrong business understanding. Worked in developing analytics solutions in 3-4 domains\\n\\nRequired Skills :\\nAbility to lead teams in agile environments, with multiple stakeholders involved\\nAbility to effectively communicate complex technical content to non-technical audience\\nSuccessful track record of structuring and leading complex analytics projects\\nProactive and passionate about resolving pain points through great design\\nSees value in iterative approach to model development\\nStrong sense of ownership and ability to build consensus\\nBelieves in culture of transparency and trust\\n\\nLocation: Bangalore / Mumbai\\n\\nWhat’s in it for you?\\nDisruptive projects: Work on ‘breakthrough’ digital-and-analytics projects to enable UPL’s vision of building a future ready organization. It involves deploying solutions to help us increase our sales, sustain our profitability, improve our speed to market, supercharge our R&D efforts, and support the way we work internally. Help us ensure we have access to the best business insights that our data analysis can offer us.\\n\\nCross functional leadership exposure: Work directly under guidance of functional leadership at UPL, on the most critical business problems for the organization (and the industry) today. It will give you exposure to a large cross-functional team (e.g.: spanning manufacturing, procurement, commercial, quality, IT/OT experts), allowing multi-functional learning in D&A deployment\\n\\nEnvironment fostering professional and personal development: Strengthen professional learning in a highly impact-oriented and meritocratic environment that is focused on delivering disproportionate business value through innovative solutions. It will be supported by on-the-job coaching from experienced domain experts, and continuous feedback from a highly motivated and capable set of peers. Comprehensive training programs for continuous development through UPL's D&A academy will help in accelerating growth opportunities.\\n\\nCome join us in this transformational journey!\\n\\n\\nLet’s collectively Change the game with Digital & Analytics!\\nRoleData Science & Machine Learning - Other\\nIndustry TypeIT Services & Consulting\\nFunctional AreaData Science & Analytics\\nEmployment TypeFull Time, Permanent\\nRole CategoryData Science & Machine Learning\\nEducation\\nUG :Any Graduate\\nKey Skills\\nTeam ManagementMLTmachine learningPython\\ndigital analyticsdata analysisdata scienceAWSstatistics\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " 'Job description\\n\\\\\\nAs a Data Scientist for Walmart Labs, you ll have the opportunity to\\nDrive data-derived insights across the wide range of retail divisions by developing advanced statistical models, machine learning algorithms and computational algorithms based on business initiatives\\nDirect the gathering of data, assessing data validity and synthesizing data into large analytics datasets to support project goals\\nUtilize big data analytics and advanced data science techniques to identify trends, patterns, and discrepancies in data. Determine additional data needed to support insights\\nBuild and train statistical models and machine learning algorithms for replication for future projects\\nCommunicate recommendations to business partners and influencing future plans based on insights\\nYour Responsibility:\\nVery good knowledge of the foundations of machine learning and statistics\\nExperience in analyzing the complex problems and translating them into data science problem\\nExperience in machine learning, supervised and unsupervised and deep learning.\\nHands on experience in Computer Visions and NLP.\\nExperience with big data analytics - identifying trends, patterns, and outliers in large volumes of data\\nStrong Experience in Python with excellent knowledge of Data Structures\\nStrong Experience with big data platforms - Hadoop (Hive, Pig, Map Reduce, HQL, Scala, Spark)\\nHands on experience with Git\\nExperience with SQL and relational databases, data warehouse\\nYour Qualifications:\\nBachelors with > 5 years of experience / Master s degree with > 3 years of experience. Educational qualifications should be preferably in Computer Science/Mathematics/Statistics or a related area. Experience should be relevant to the role\\nMust have:\\nGood knowledge of Probability and Statistics, Linear Algebra, Convex Optimization, Algorithms\\nGood knowledge of Machine Learning fundamentals (Supervised learning, Unsupervised learning, Regression, Classification, Clustering, Maximum Likelihood Estimation, Regularization, ...)\\nGood knowledge of ML models like Logistic Regression, SVMs, Random Forests, Gaussian Mixture Models among others\\nGood knowledge of Deep Learning models and fundamentals like CNN, LSTM and Sequence Models, Word Embeddings (Word2Vec or Glove, BERT,...)\\nGood knowledge of a Deep Learning framework- Tensorflow or PyTorch\\nGood knowledge of Python including numpy, sklearn, pandas\\nA very strong problem-solving mindset, with eagerness to learn (and this can compensate for weakness in any of the above points)\\nRoleTechnical Lead\\nIndustry TypeIT Services & Consulting\\nFunctional AreaEngineering - Software & QA\\nEmployment TypeFull Time, Permanent\\nRole CategorySoftware Development\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nComputer scienceComputer visiondeep learningData analysisArtificial IntelligenceMachine learningData structuresNatural language processingSQLPython',\n",
       " 'Job description\\n  Understand the data sources in Walmart.\\nSample-extract-clean-transform data, detect outliers. Simply build efficient feature extraction, training and prediction pipelines.\\nDevelop machine learning models for the business use cases in Walmart. This will include various ML models spanning both supervised and unsupervised learning.\\nDesigning and developing MLOps for machine learning and deep learning systems.\\nWrite functions for statistical analysis of data.\\nBuild compelling data visualisations and interactive dashboards for monitoring and sharing of business KPIs and data insights.\\nConvert developed models to deployable artefacts.\\nConduct experiments to improve deployed models.\\nProvide innovative solutions to the business problems, and drive patents and publications on this work, popularise the work by demonstrations and blogs.\\nRead and replicate latest research with an eye towards applying it to problems in Walmart\\nWork in an agile environment to deliver high quality solutions, with globally distributed and remote teams\\nPromote and support company policies, procedures, mission and uphold the values and standards of ethics and integrity\\nOur ideal candidate is an energetic, self-motivated individual, excited by AL/ML and focused on solving customer problems. She/he is a quick learner, out-of-the-box thinker and a good problem solver. She/he is someone who thrives in a fun, fast-paced, and dynamic environment.\\nPosition Requirements:\\nMinimum qualifications:\\nShould have strong computer science fundamentals in data structures and algorithms, object oriented programming\\nKnowledge of the foundations of machine learning and statistics\\nA continuous drive to explore, improve, enhance, automate and optimise systems and tools.\\nExposure to cloud infrastructure, such as Azure, GCP.\\nExperience in building of large scale data pipelines using big data technologies (i. e. Spark / Kafka / Hadoop / Hive / Airflow)\\nStrong software development skills in languages such as Python or Scala.\\nExposure to open source ML frameworks like scikit learn, keras, SparkML lib, etc.\\nExperience in building of large scale data pipelines using big data technologies (i.e. Spark / Kafka / Cassandra / Hadoop / Hive / Presto / Airflow).\\nExperience in systems design, algorithms, and distributed systems.\\nRoleTechnical Lead\\nIndustry TypeIT Services & Consulting\\nFunctional AreaEngineering - Software & QA\\nEmployment TypeFull Time, Permanent\\nRole CategorySoftware Development\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nComputer sciencecassandraMachine learningAgileData structuresOpen sourceDistribution systemAnalyticsMonitoringPython',\n",
       " \"Job description\\nAbout UPL:\\nUPL is focused on emerging as a premier global provider of total crop solutions designed to secure the worlds long-term food supply. Winning farmers hearts across the globe, while leading the way with innovative products and services that make agriculture sustainable, UPL is the fastest growing company in the industry. UPL has a rich history of 50+ years with presence in 120+ countries. Based on the recognition that humankind is one community, UPL’s overarching commitment is to improve areas of its presence, workplace, and customer engagement.\\n\\nOur purpose is ‘OpenAg’. An Open agriculture network that feeds sustainable growth for all. No limits, no borders.\\n\\nIn order to create sustainable food chain, UPL is now working to build a future-ready, analytics-driven organization that will be even more efficient, more innovative, and more agile. We are setting up “Digital and Analytics” CoE to work on some disruptive projects that will have an impact that matters for the planet. It will help us reimagine our business to ensure the best outcomes for growers, consumers, employees, and our planet.\\nWork with us to get exposure to cutting-edge solutions in digital & advanced analytics, mentorship from senior leaders & domain experts, and access to a great work environment.\\n\\nJob Responsibilities:\\n\\nThe Expert Data Scientist will use both management experience and data science expertise to lead teams of data scientists across multiple analytics projects. This person will be an integral part of conceptualizing, scoping and delivering complex analytics projects. They will oversee the development, testing and maintenance of analytical models which mimic business decisions. This person will work closely with the CoE leadership and business units in delivering impact through analytics. Additionally, this person will be responsible for continuously identifying opportunities to improve the ways of working and structuring within the analytics center of excellence.\\nManage analytics strategy across multiple use cases\\nProvides analytical expertise in the process of model development, refining and implementation in a variety of analytics problems spread across a variety of domains\\nOversees large teams of associate and mid level data scientists, de-bottlenecking issues related to project execution\\nWork closely with translators and business teams to develop and implement analytics solutions\\nCollaborate with data engineers & architects to implement and deploy scalable solutions\\nCommunicate results to diverse technical and non technical audiences\\nActively drive a culture of knowledge building and sharing within the team. Encourage continuous innovation and out of the box thinking.\\n\\nREQUIRED EDUCATION AND EXPERIENCE:\\nMaster’s degree in Computer Science, Statistics, Math, Operations Research, Economics or a related field\\nExperience in programming in at least 2 languages\\nSound theoretical and practical knowledge of working with advanced statistical algorithms, including machine learning techniques\\nAt least 6 years of experience of working in analytics and leading teams\\nWorked in developing analytics solutions in 3-4 domains\\n\\nRequired Skills :\\nAbility to lead teams in agile environments, with multiple stakeholders involved\\nAbility to effectively communicate complex technical content to non-technical audience\\nSuccessful track record of structuring and leading complex analytics projects\\nProactive and passionate about resolving pain points through great design\\nSees value in iterative approach to model development\\nStrong sense of ownership and ability to build consensus\\nBelieves in culture of transparency and trust\\n\\nLocation: Bangalore / Mumbai\\n\\nWhat’s in it for you?\\n\\nDisruptive projects: Work on ‘breakthrough’ digital-and-analytics projects to enable UPL’s vision of building a future ready organization. It involves deploying solutions to help us increase our sales, sustain our profitability, improve our speed to market, supercharge our R&D efforts, and support the way we work internally. Help us ensure we have access to the best business insights that our data analysis can offer us.\\n\\nCross functional leadership exposure: Work directly under guidance of functional leadership at UPL, on the most critical business problems for the organization (and the industry) today. It will give you exposure to a large cross-functional team (e.g.: spanning manufacturing, procurement, commercial, quality, IT/OT experts), allowing multi-functional learning in D&A deployment\\n\\nEnvironment fostering professional and personal development: Strengthen professional learning in a highly impact-oriented and meritocratic environment that is focused on delivering disproportionate business value through innovative solutions. It will be supported by on-the-job coaching from experienced domain experts, and continuous feedback from a highly motivated and capable set of peers. Comprehensive training programs for continuous development through UPL's D&A academy will help in accelerating growth opportunities.\\n\\nCome join us in this transformational journey!\\n\\nLet’s collectively Change the game with Digital & Analytics!\\nRoleData Science & Machine Learning - Other\\nIndustry TypeIT Services & Consulting\\nFunctional AreaData Science & Analytics\\nEmployment TypeFull Time, Permanent\\nRole CategoryData Science & Machine Learning\\nEducation\\nUG :Any Graduate\\nKey Skills\\nteam leadMLTmachine learningawsPython\\ndata scienceazurestatistics\\nSkills highlighted with ‘‘ are preferred keyskills\",\n",
       " 'Job description\\nResponsibilities :\\nBuilding advanced statistical models, algorithms and trend analysis in order to discover predictive insights related to network and business objectives\\nTranslate data algorithms and complex ideas into impactful management insights and solutions\\nTranslate operator business objectives into business intelligence trough regressive data analytics\\nWorking on BigData tools and technologies to sustain our continued operational transformation objectives and market leadership\\nResearch and develop approaches on how to improve business processes and customers experience by using our vast amounts of data.\\n\\n\\nYou will bring\\nGood knowledge of statistical analysis, theory of probabilities, design of experiments and machine learning.\\nAcuity for business flow understanding and expertise in data preparation-data mining and pre-processing.\\nGood command of programming language and software environment for statistical analysis, graphics representation and reporting i.e. R, Python;\\n\\nRoleSoftware Development - Other\\nIndustry TypeElectronic Components / Semiconductors\\nFunctional AreaEngineering - Software & QA\\nEmployment TypeFull Time, Permanent\\nRole CategorySoftware Development\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nGraphicsBiddingGoogle AnalyticsData managementSocial networkingGoogle AdWordsHTMLBusiness intelligenceData miningCRM',\n",
       " 'Job description\\nA Senior Data Scientist will aid in implementing Science solutions for applications driven by artificial intelligence and machine learning in the retail domain. A Senior Data Scientist will work closely with other Team Member s to continuously learn more about our technology and particularly develop an understanding of the various processes and best practices, such as Scrum.\\nResponsibilities:\\nPrimary\\nDevelop and deploy applications independently based on Machine Learning, Deep Learning etc.\\nCommunicate clearly with other team members.\\nParticipate in agile process of product development.\\nSecondary\\nReview code developed by team\\nKeep abreast of advances in technology\\nTertiary\\nActive participant in team meetings\\n\\nRequirements:\\nBachelors or Masters in Computer Science, or in a related Math or Computer Engineering major.\\n2+ years of experience in developing code in industry or equivalent college experience.\\nSignificant knowledge of Machine Learning Algorithms and ML Libraries.\\nProficient in one or more of Python, Scala, C++ or equivalent programming languages.\\nExperience working with Big Data Software like Spark, Hive, Hbase, Kafka.\\nWell versed with fundamentals of computer science, data structures and algorithms and applied math and/or Statistics.\\nAbility to develop and execute processes for complete CI/CD pipelines\\nExcellent written and verbal communication skills\\nDevelop production quality code for algorithms\\nReliable production deployments\\nIncorporate best engineering practices\\nRoleBack End Developer\\nIndustry TypeRetail\\nFunctional AreaEngineering - Software & QA\\nEmployment TypeFull Time, Permanent\\nRole CategorySoftware Development\\nEducation\\nUG :Any Graduate\\nPG :Any Postgraduate\\nKey Skills\\nComputer scienceC++Artificial IntelligenceMachine learningSCALAAgileData structuresScrumPythonHBase']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b987b592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print(len(job_description))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698823a6",
   "metadata": {},
   "source": [
    "# Creating a dataframe for the Data Analyst Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ef764a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=pd.DataFrame({})\n",
    "jobs['title']=job_titles[:10]\n",
    "jobs['company']=companies_names[:10]\n",
    "jobs['job_description']=job_description[:10]\n",
    "jobs['location']=locations_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a845ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_description</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>UPL</td>\n",
       "      <td>Job description\\nAbout upl:\\n\\nUPL is focused ...</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst / Product Analyst / Business Analyst</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Job description\\n  As a Senior Data Scientists...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>SAP India Pvt.Ltd</td>\n",
       "      <td>Job description\\nWHAT YOU'LL DO\\nWork along wi...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst / Business Analyst</td>\n",
       "      <td>UPL</td>\n",
       "      <td>Job description\\nAbout UPL:\\nUPL is focused on...</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst 1</td>\n",
       "      <td>UPL</td>\n",
       "      <td>Job description\\nAbout upl:\\nUPL is focused on...</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Financial Data Analyst</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Job description\\n\\\\nAs a Data Scientist for Wa...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst III</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>Job description\\n  Understand the data sources...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>data analyst/ data analytics / Business analys...</td>\n",
       "      <td>UPL</td>\n",
       "      <td>Job description\\nAbout UPL:\\nUPL is focused on...</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai (All Areas)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sr Data Analyst - SQL/Python</td>\n",
       "      <td>Ericsson</td>\n",
       "      <td>Job description\\nAbout upl:\\n\\nUPL is focused ...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst - SQL/Tableau</td>\n",
       "      <td>Target</td>\n",
       "      <td>Job description\\n  As a Senior Data Scientists...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title            company  \\\n",
       "0                                Senior Data Analyst                UPL   \n",
       "1  Data Analyst / Product Analyst / Business Analyst            Walmart   \n",
       "2                    Data Analyst / Business Analyst  SAP India Pvt.Ltd   \n",
       "3                    Data Analyst / Business Analyst                UPL   \n",
       "4                                     Data Analyst 1                UPL   \n",
       "5                             Financial Data Analyst            Walmart   \n",
       "6                                   Data Analyst III            Walmart   \n",
       "7  data analyst/ data analytics / Business analys...                UPL   \n",
       "8                       Sr Data Analyst - SQL/Python           Ericsson   \n",
       "9                  Senior Data Analyst - SQL/Tableau             Target   \n",
       "\n",
       "                                     job_description  \\\n",
       "0  Job description\\nAbout upl:\\n\\nUPL is focused ...   \n",
       "1  Job description\\n  As a Senior Data Scientists...   \n",
       "2  Job description\\nWHAT YOU'LL DO\\nWork along wi...   \n",
       "3  Job description\\nAbout UPL:\\nUPL is focused on...   \n",
       "4  Job description\\nAbout upl:\\nUPL is focused on...   \n",
       "5  Job description\\n\\\\nAs a Data Scientist for Wa...   \n",
       "6  Job description\\n  Understand the data sources...   \n",
       "7  Job description\\nAbout UPL:\\nUPL is focused on...   \n",
       "8  Job description\\nAbout upl:\\n\\nUPL is focused ...   \n",
       "9  Job description\\n  As a Senior Data Scientists...   \n",
       "\n",
       "                                  location  \n",
       "0  Bangalore/Bengaluru, Mumbai (All Areas)  \n",
       "1                      Bangalore/Bengaluru  \n",
       "2                      Bangalore/Bengaluru  \n",
       "3  Bangalore/Bengaluru, Mumbai (All Areas)  \n",
       "4  Bangalore/Bengaluru, Mumbai (All Areas)  \n",
       "5                      Bangalore/Bengaluru  \n",
       "6                      Bangalore/Bengaluru  \n",
       "7  Bangalore/Bengaluru, Mumbai (All Areas)  \n",
       "8                      Bangalore/Bengaluru  \n",
       "9                      Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f484a31",
   "metadata": {},
   "source": [
    "So here we can see that we have created the dataset for Data scientist jobs named job1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "62cd45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f34302",
   "metadata": {},
   "source": [
    "Question 3\n",
    "\n",
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "61c7b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\arti\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "27bc17ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.naukri.com\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3f1849d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"6c067f36-8be6-4566-ab4c-b18dc314ea45\")>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_job = driver.find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[1]/div/div/div/input\")\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "aad0a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "125eeb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"184db22e-f3f4-4896-80b6-9f9b9d4fafdd\")>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_btn= driver .find_element_by_xpath(\"/html/body/div/div[2]/div[3]/div/div/div[5]/div/input\")\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "78d2fa9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"3675938f-8d16-4233-91c0-e9cd0c0bc3dd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"dd070168-62d3-427a-8b03-5ec835282e24\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"671fa04e-d885-4854-965c-39715b3d75cc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"40e3ef52-e7a4-40be-a379-9452b6b897e6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"88cea848-26b1-4f75-a638-2574771a7657\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"e2041cab-ccbe-4f4c-9d41-8ec40b2f81a2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"5e0dbe8a-df0e-4e46-8ce2-2d4e7f85cacc\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"4fc3d932-61bf-409b-afd8-1554f3015fa3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"8f01f034-3a61-4d30-9f51-f16a5573a924\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"af53a3fb-3c12-49ed-be9e-402f9aaef216\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"aff89de6-ec60-482a-afaa-405db7c7c0d2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"3e5fa60d-93b2-4848-8d4a-0a314808db96\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"74ef0fea-4609-4d9e-b08f-e4e78074fe29\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"41cff3f9-eadf-4c74-8637-22c864ba7025\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"c15df40c-d569-4a33-988e-d1b913a4fcdd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"dbee88ff-768f-4b6c-be4b-e5ba50b1707a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"a122dcbb-c417-4523-a6d7-761c5ba3248f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"79d06277-069a-47bd-a79a-0a17a58f4277\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"223ea09a-2385-4b6e-9af7-09a5200f60f7\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"5b2c7623-b999-41ae-bd41-aaea60599cdb\")>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so let's extract all the tags having the job titles\n",
    "title_t1=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "title_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9085527a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Scientist',\n",
       " 'Junior Data Scientist',\n",
       " 'Data Scientist - Internet Jobs - II',\n",
       " 'Associate Scientist - Data Engineering',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist (freelance)',\n",
       " 'Data Scientist',\n",
       " 'Associate Data Scientist',\n",
       " 'Hiring For Data Analyst and Data Scientist For Gurgaon Location',\n",
       " 'Data Scientist || Software Company || Immediate Joiners To max 30 Days']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the text of the job title  from the tags\n",
    "job_titles=[]\n",
    "for i in title_t1:\n",
    "    if i.text is None:\n",
    "        job_titles.append('Not')\n",
    "    else:\n",
    "        job_titles.append(i.text)\n",
    "job_titles[:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "22a33408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"6338940e-f157-49ef-9953-c97f4d89b2cf\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"4dd1c90f-3599-4697-8d62-df9c718ddece\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"120e972e-cf53-408b-8c3e-6458ae55e0f5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"b5d4f941-79e2-45e8-ab48-2baf937a02d6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"4f510166-b888-444d-adec-1c78ad7667b8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"f21fbac8-9d61-435d-bf95-0aa348a326ad\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"c0d63fea-d964-4a41-a9ca-94cbd3caf8c2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"f3e8ec35-ad92-498b-a76e-cb5d5b5a99f2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"5c2329f5-5e92-45e8-98ff-1371cf921067\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"9ec84f19-a581-4737-adf2-972b02bca333\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"87a593a5-1b34-4815-9c4c-858796d7ff75\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"5b1e3ff8-11b8-419a-a1ae-b8a74019bd88\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"d0167ac9-1afe-4673-802c-c4737a3cd573\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"89ff4ca8-83a4-4760-a10c-7122b9bfeb19\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"c9d2dedc-7753-4dce-af77-01be17731150\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"9665f39d-568f-44c0-814f-5955b1e64587\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"4947912c-195a-4c4b-acbc-5d6b6337c9df\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"ce6ba051-4f0a-482d-849d-390b7e0a8471\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"726baa5b-06e8-4bb7-85a8-adffb75c88d3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"1696a7ed-d5e3-4f11-a21c-f8c7dd7bfd60\")>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets extract all the tags having company names\n",
    "company_t1=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "company_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fb0fad5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ashkom Media India Private Limited',\n",
       " 'EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED',\n",
       " 'Jobs Territory',\n",
       " 'AXA Technology Services India Pvt. Ltd',\n",
       " 'Orbit Techsol (W) Pvt Ltd',\n",
       " '2Coms',\n",
       " 'BlackBuck',\n",
       " 'Optum',\n",
       " 'Shadow Placements',\n",
       " 'Skyleaf Consultants']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we will extract the text from the tags by looping over these tags\n",
    "companies_names=[]\n",
    "\n",
    "for i in company_t1:\n",
    "    companies_names.append(i.text)\n",
    "companies_names[:10]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dcc4cbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"4113ca3d-228c-4d61-8910-903f32e14f7f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"c89c56fc-59ed-483a-bbd6-794297f56e56\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"af760fb7-add6-480b-95fb-257ce48ba1be\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"828014af-d38e-43b1-bc4c-3d3ed4da8329\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"ee09b174-8698-410c-8721-c656b4a15b86\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"3bbddce0-79e9-4b4a-b2d0-784d0fcd1df8\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"11270502-2240-4b5e-b33c-9a5ea7d4217b\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"ccf6967b-60ca-4347-8d0a-6bcee1f02b8d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"8f095532-7d26-4805-810d-bfb1c048d6b0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"456113eb-f6f6-427e-8832-43d039b5c9e1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"1cf145c8-880d-49ba-a923-055f46d83b9d\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"839488b2-4e43-44af-b757-b06370ea4a28\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"18f946c4-db5b-4fc5-948c-08d6b16a385a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"bb77fdb9-4dc3-4ac8-804f-ae36a7003065\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"47c6528b-d09e-4e37-bd72-5f6ad9441777\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"e4d95757-4711-475c-8708-b6b63c796b05\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"8693ba68-e1d3-4c4b-aa99-8e279b853c27\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"5235955b-3ccf-45f1-9f95-9e69580114f9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"45f62c9d-8586-4224-99a1-fc5798dd73be\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"4875e883-9145-4512-8d4d-adb30cb0b967\")>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so lets extract  all the tags having the experience required data\n",
    "experience_t1=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience'] //span\")\n",
    "experience_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8bcf905f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-6 Yrs',\n",
       " '1-2 Yrs',\n",
       " '3-6 Yrs',\n",
       " '2-5 Yrs',\n",
       " '4-9 Yrs',\n",
       " '2-7 Yrs',\n",
       " '3-7 Yrs',\n",
       " '1-5 Yrs',\n",
       " '3-7 Yrs',\n",
       " '3-8 Yrs']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no we will extract the text  from these tags only by one by looping over these tags\n",
    "experience_list=[]\n",
    "for i in experience_t1:\n",
    "    experience_list.append(i.text)\n",
    "experience_list[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "157f584b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"996e29f2-adde-4e3b-ba1a-b238f0d78f63\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"5cfbb82d-9d43-4e79-82fc-4102bbc634a4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"de00c967-ee08-4ef5-8ac8-61defde44ff6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"e2ced40a-3fcf-4ceb-b551-c2ade59198e6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"c5f4ce10-b91e-45d6-b449-508cbc27bfd6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"c464a72a-4b22-44f9-88d4-bc1cab51b593\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"b72221c4-3b1e-4b10-b1c6-811eef3fbf05\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"b5e6bcca-bf1b-4518-9e4a-71556c9ea2ec\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"0d91134b-4c28-414a-9f3c-beb35df1570a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"a72cf28e-55f4-4e0f-9033-3ffc58395156\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"741216e2-a63e-427f-beab-2ca8f79cd7db\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"58dd2f08-3788-4140-948d-d565b953fca6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"671e358a-579c-44ce-81df-9f481ead799f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"00d94768-7275-4231-acaf-e6046026157a\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"07a2ef0c-b129-421d-b833-825d13daf334\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"86852ff7-e022-4f28-bbce-5986f7b348c6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"448ceb05-6980-480f-a1b1-f3a72a94e5b4\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"40468ac9-5096-4f8b-88c3-784bdb0dc7e6\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"066ba2e1-0a7f-4ab8-ba0c-cc7961919374\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"ebe64de8b3752209c87f149fc064d7cd\", element=\"f9f87baf-06e8-42d5-b316-aea0515756b0\")>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# So lets extract all the tags having locations\n",
    "locations_t1=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span\")\n",
    "locations_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2cb7a575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Noida, Bangalore/Bengaluru',\n",
       " 'Noida',\n",
       " 'Bangalore/Bengaluru, Delhi / NCR, Mumbai (All Areas)',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Delhi / NCR',\n",
       " 'New Delhi, Delhi',\n",
       " 'Gurgaon, Bengaluru',\n",
       " 'Gurgaon/Gurugram',\n",
       " 'Noida, Gurgaon/Gurugram, Delhi / NCR',\n",
       " 'Gurgaon/Gurugram, Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we wil extract the text from these tags only by one by looping over these tags\n",
    "locations_list=[]\n",
    "for i in locations_t1:\n",
    "    locations_list.append(i.text)\n",
    "locations_list[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f17fc642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#So lets check th length of ech element.\n",
    "print(len(job_titles[:10])),print(len(companies_names[:10])),print(len(experience_list[:10])),print(len(locations_list[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c721addf",
   "metadata": {},
   "source": [
    "Creating a DataFarme for the Data Analyst jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "256c0ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs2=pd.DataFrame({})\n",
    "jobs2['title']=job_titles[:10]\n",
    "jobs2['company']=companies_names[:10]\n",
    "jobs2['experience_required']=experience_list[:10]\n",
    "jobs2['location']=locations_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dba629d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ashkom Media India Private Limited</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Internet Jobs - II</td>\n",
       "      <td>Jobs Territory</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Scientist - Data Engineering</td>\n",
       "      <td>AXA Technology Services India Pvt. Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Orbit Techsol (W) Pvt Ltd</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist (freelance)</td>\n",
       "      <td>2Coms</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>New Delhi, Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Gurgaon, Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hiring For Data Analyst and Data Scientist For...</td>\n",
       "      <td>Shadow Placements</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist || Software Company || Immediat...</td>\n",
       "      <td>Skyleaf Consultants</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                     Data Scientist   \n",
       "1                              Junior Data Scientist   \n",
       "2                Data Scientist - Internet Jobs - II   \n",
       "3             Associate Scientist - Data Engineering   \n",
       "4                                     Data Scientist   \n",
       "5                         Data Scientist (freelance)   \n",
       "6                                     Data Scientist   \n",
       "7                           Associate Data Scientist   \n",
       "8  Hiring For Data Analyst and Data Scientist For...   \n",
       "9  Data Scientist || Software Company || Immediat...   \n",
       "\n",
       "                                          company experience_required  \\\n",
       "0              Ashkom Media India Private Limited             3-6 Yrs   \n",
       "1  EASY DATA ANALYTICS TECHNOLOGY PRIVATE LIMITED             1-2 Yrs   \n",
       "2                                  Jobs Territory             3-6 Yrs   \n",
       "3          AXA Technology Services India Pvt. Ltd             2-5 Yrs   \n",
       "4                       Orbit Techsol (W) Pvt Ltd             4-9 Yrs   \n",
       "5                                           2Coms             2-7 Yrs   \n",
       "6                                       BlackBuck             3-7 Yrs   \n",
       "7                                           Optum             1-5 Yrs   \n",
       "8                               Shadow Placements             3-7 Yrs   \n",
       "9                             Skyleaf Consultants             3-8 Yrs   \n",
       "\n",
       "                                            location  \n",
       "0                         Noida, Bangalore/Bengaluru  \n",
       "1                                              Noida  \n",
       "2  Bangalore/Bengaluru, Delhi / NCR, Mumbai (All ...  \n",
       "3                                   Gurgaon/Gurugram  \n",
       "4                                        Delhi / NCR  \n",
       "5                                   New Delhi, Delhi  \n",
       "6                                 Gurgaon, Bengaluru  \n",
       "7                                   Gurgaon/Gurugram  \n",
       "8               Noida, Gurgaon/Gurugram, Delhi / NCR  \n",
       "9              Gurgaon/Gurugram, Bangalore/Bengaluru  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6105ba2",
   "metadata": {},
   "source": [
    "We can see that we have created the dataset named jobs2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c42c0ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e01202",
   "metadata": {},
   "source": [
    "# Question 4  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ea503",
   "metadata": {},
   "source": [
    "Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4861269f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\arti\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8331f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d230ecde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"bf0fbfbc242c45b84d0c158125a97d0a\", element=\"78ece304-bb31-4a43-a310-522d834a1dad\")>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_g= driver.find_element_by_xpath(\"//input[@type='text']\")\n",
    "search_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2c528614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_g.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b0b72f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"bf0fbfbc242c45b84d0c158125a97d0a\", element=\"94253b34-a5a5-48d5-90f4-7d8521f2cf4f\")>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "66918b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_class_name('L0Z3Pu')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4a49f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_name=[]\n",
    "Price=[]\n",
    "P_desc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "859785f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    b_name=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    p_desc=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    price =driver.find_elements_by_xpath(\"//div[@class='_25b18c']\")\n",
    "    \n",
    "    for j  in b_name:\n",
    "        B_name.append(j.text)\n",
    "    B_name[:100]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in p_desc:\n",
    "        P_desc.append(k.text)\n",
    "    P_desc[:100] \n",
    "    \n",
    "    \n",
    "    for l in price:\n",
    "        Price.append(l.text)\n",
    "    Price[:100] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c383c924",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Singco India',\n",
       " 'Singco India',\n",
       " 'Elligator',\n",
       " 'PIRASO',\n",
       " 'DAHAAZIL',\n",
       " 'Fastrack',\n",
       " 'New Specs',\n",
       " 'VINCENT CHASE',\n",
       " 'Elligator',\n",
       " 'PIRASO',\n",
       " 'PIRASO',\n",
       " 'VINCENT CHASE',\n",
       " 'Lee Topper',\n",
       " 'SHAAH COLLECTIONS',\n",
       " 'PIRASO',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Fastrack',\n",
       " 'Fastrack',\n",
       " 'PIRASO',\n",
       " 'Roadster',\n",
       " 'Lee Topper',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Fastrack',\n",
       " 'Resist',\n",
       " 'kingsunglasses',\n",
       " 'New Specs',\n",
       " 'hipe',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'kingsunglasses',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'SRPM',\n",
       " 'john jacobs',\n",
       " 'Singco India',\n",
       " 'New Specs',\n",
       " 'DEIXELS',\n",
       " 'NuVew',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'SUNBEE',\n",
       " 'Fastrack',\n",
       " 'Roadster',\n",
       " 'Singco India',\n",
       " 'Singco India',\n",
       " 'Elligator',\n",
       " 'PIRASO',\n",
       " 'DAHAAZIL',\n",
       " 'Fastrack',\n",
       " 'New Specs',\n",
       " 'VINCENT CHASE',\n",
       " 'Elligator',\n",
       " 'PIRASO',\n",
       " 'PIRASO',\n",
       " 'VINCENT CHASE',\n",
       " 'Lee Topper',\n",
       " 'SHAAH COLLECTIONS',\n",
       " 'PIRASO',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Fastrack',\n",
       " 'Fastrack',\n",
       " 'PIRASO',\n",
       " 'Roadster',\n",
       " 'Lee Topper',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Fastrack',\n",
       " 'Resist',\n",
       " 'kingsunglasses',\n",
       " 'New Specs',\n",
       " 'hipe',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'kingsunglasses',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'SRPM',\n",
       " 'john jacobs',\n",
       " 'Singco India',\n",
       " 'New Specs',\n",
       " 'DEIXELS',\n",
       " 'NuVew',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'SUNBEE',\n",
       " 'Fastrack',\n",
       " 'Roadster',\n",
       " 'Singco India',\n",
       " 'Singco India',\n",
       " 'Elligator',\n",
       " 'PIRASO',\n",
       " 'DAHAAZIL',\n",
       " 'Fastrack',\n",
       " 'New Specs',\n",
       " 'VINCENT CHASE',\n",
       " 'Elligator',\n",
       " 'PIRASO',\n",
       " 'PIRASO',\n",
       " 'VINCENT CHASE',\n",
       " 'Lee Topper',\n",
       " 'SHAAH COLLECTIONS',\n",
       " 'PIRASO',\n",
       " 'ROZZETTA CRAFT',\n",
       " 'Fastrack',\n",
       " 'Fastrack',\n",
       " 'PIRASO',\n",
       " 'Roadster']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_name[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d57035fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(B_name[:100])),print(len(Price[:100])),print(len(P_desc[:100]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1016b8",
   "metadata": {},
   "source": [
    "# Creating a dataframe of the above data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "35016cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_gl=pd.DataFrame({})\n",
    "sun_gl['Brand_name']=B_name[:100]\n",
    "sun_gl['P_price']=Price[:100]\n",
    "sun_gl['Pr_desc']=P_desc[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8de42a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>P_price</th>\n",
       "      <th>Pr_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>₹630₹2,99978% off</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>₹239₹69965% off</td>\n",
       "      <td>UV Protection, Riding Glasses, Others Aviator,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>₹295₹2,49588% off</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹249₹1,59984% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DAHAAZIL</td>\n",
       "      <td>₹219₹99978% off</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>₹719₹89920% off</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹264₹2,59989% off</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>₹649₹1,99967% off</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>₹224₹1,29982% off</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>₹280₹2,59989% off</td>\n",
       "      <td>UV Protection Shield Sunglasses (Free Size)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Brand_name            P_price  \\\n",
       "0     Singco India  ₹630₹2,99978% off   \n",
       "1     Singco India    ₹239₹69965% off   \n",
       "2        Elligator  ₹295₹2,49588% off   \n",
       "3           PIRASO  ₹249₹1,59984% off   \n",
       "4         DAHAAZIL    ₹219₹99978% off   \n",
       "..             ...                ...   \n",
       "95  ROZZETTA CRAFT    ₹719₹89920% off   \n",
       "96        Fastrack  ₹264₹2,59989% off   \n",
       "97        Fastrack  ₹649₹1,99967% off   \n",
       "98          PIRASO  ₹224₹1,29982% off   \n",
       "99        Roadster  ₹280₹2,59989% off   \n",
       "\n",
       "                                              Pr_desc  \n",
       "0   Gradient, Toughened Glass Lens, UV Protection ...  \n",
       "1   UV Protection, Riding Glasses, Others Aviator,...  \n",
       "2                 UV Protection Round Sunglasses (54)  \n",
       "3               UV Protection Aviator Sunglasses (54)  \n",
       "4   UV Protection, Night Vision, Riding Glasses Wa...  \n",
       "..                                                ...  \n",
       "95      UV Protection Wayfarer Sunglasses (Free Size)  \n",
       "96              UV Protection Aviator Sunglasses (54)  \n",
       "97   UV Protection Rectangular Sunglasses (Free Size)  \n",
       "98  UV Protection, Gradient Retro Square Sunglasse...  \n",
       "99        UV Protection Shield Sunglasses (Free Size)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sun_gl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087aff52",
   "metadata": {},
   "source": [
    "We can see that we have created the dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ffb996a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c4131f",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df38f1c",
   "metadata": {},
   "source": [
    "Scrape 100 reviews data from flipkart.com for iphone11 phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e28bca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\arti\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "253fdff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-%20earpods-power%02adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC%20TSVZAXUHGREPBFGI&marketplace\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda30c1",
   "metadata": {},
   "source": [
    "Now I m scrapping the attributes:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a293daf",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a253c0",
   "metadata": {},
   "source": [
    "Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "afc253b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\arti\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a882e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.flipkart.com/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "45f32efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"6b527e5e30adaaf13f133d316a1261f0\", element=\"15af6a99-2a65-4170-9b16-dae689f9393c\")>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_g= driver.find_element_by_xpath(\"//input[@type='text']\")\n",
    "search_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c95e3d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_g.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2f12b6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"6b527e5e30adaaf13f133d316a1261f0\", element=\"c1ead027-a70b-40e0-a726-b20d3ccb2001\")>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9f93e123",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_class_name('L0Z3Pu')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "90ec3442",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_name=[]\n",
    "Price=[]\n",
    "P_desc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "290863d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    b_name=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    p_desc=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    price =driver.find_elements_by_xpath(\"//div[@class='_25b18c']\")\n",
    "    \n",
    "    for j  in b_name:\n",
    "        B_name.append(j.text)\n",
    "    B_name[:100]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in p_desc:\n",
    "        P_desc.append(k.text)\n",
    "    P_desc[:100] \n",
    "    \n",
    "    \n",
    "    for l in price:\n",
    "        Price.append(l.text)\n",
    "    Price[:100] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "30545577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(B_name[:100])),print(len(Price[:100])),print(len(P_desc[:100]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2786f",
   "metadata": {},
   "source": [
    "# Creating a dataframe of the above data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2420e640",
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_gl=pd.DataFrame({})\n",
    "sun_gl['Brand_name']=B_name[:100]\n",
    "sun_gl['P_price']=Price[:100]\n",
    "sun_gl['Pr_desc']=P_desc[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "49557c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>P_price</th>\n",
       "      <th>Pr_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DUNKASTON</td>\n",
       "      <td>₹379₹1,49974% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>white tape</td>\n",
       "      <td>₹675₹1,59957% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>₹198₹99980% off</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>₹742₹3,49978% off</td>\n",
       "      <td>STYLISH MENS BLACK AND WHITE SNEAKER Sneakers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹295₹1,29977% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>T-ROCK</td>\n",
       "      <td>₹650₹99934% off</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>₹499₹1,49966% off</td>\n",
       "      <td>STYLISH MENS BLACK AND WHITE SNEAKER Sneakers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Cross Finger</td>\n",
       "      <td>₹299₹49940% off</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SPARX</td>\n",
       "      <td>₹351₹99964% off</td>\n",
       "      <td>Stylish Comfortable Lightweight, Breathable Wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bacan</td>\n",
       "      <td>₹299₹1,29976% off</td>\n",
       "      <td>Lattest Sneakers Shoe Sneakers For Men</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand_name            P_price  \\\n",
       "0               DUNKASTON  ₹379₹1,49974% off   \n",
       "1              white tape  ₹675₹1,59957% off   \n",
       "2                URBANBOX    ₹198₹99980% off   \n",
       "3   HRX by Hrithik Roshan  ₹742₹3,49978% off   \n",
       "4                  BRUTON  ₹295₹1,29977% off   \n",
       "..                    ...                ...   \n",
       "95                 T-ROCK    ₹650₹99934% off   \n",
       "96                 BRUTON  ₹499₹1,49966% off   \n",
       "97           Cross Finger    ₹299₹49940% off   \n",
       "98                  SPARX    ₹351₹99964% off   \n",
       "99                  Bacan  ₹299₹1,29976% off   \n",
       "\n",
       "                                              Pr_desc  \n",
       "0                                    Sneakers For Men  \n",
       "1                                    Sneakers For Men  \n",
       "2       Modern Trendy Sneakers Shoes Sneakers For Men  \n",
       "3   STYLISH MENS BLACK AND WHITE SNEAKER Sneakers ...  \n",
       "4                                    Sneakers For Men  \n",
       "..                                                ...  \n",
       "95      Modern Trendy Sneakers Shoes Sneakers For Men  \n",
       "96  STYLISH MENS BLACK AND WHITE SNEAKER Sneakers ...  \n",
       "97                                   Sneakers For Men  \n",
       "98  Stylish Comfortable Lightweight, Breathable Wa...  \n",
       "99             Lattest Sneakers Shoe Sneakers For Men  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sun_gl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77a1e43",
   "metadata": {},
   "source": [
    "We have created the dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "eac9974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b61cd52",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85199420",
   "metadata": {},
   "source": [
    "Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0a2830",
   "metadata": {},
   "source": [
    "Scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1f3c938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\arti\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b1034f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.myntra.com/shoes\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "58656e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appplying the price filter\n",
    "filter_button=driver.find_elements_by_xpath(\"//label[@class='common-customerCheckbox vertical-filters-label']\")\n",
    "for i in filter_button:\n",
    "    if i.text==\"Rs.7149 to Rs. 14099\":\n",
    "        i.click()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c897e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "B_name=[]\n",
    "Price=[]\n",
    "P_desc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9deaa35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    b_name=driver.find_elements_by_xpath(\"//h1[@class='pdp-title']\")\n",
    "    p_desc=driver.find_elements_by_xpath(\"//h1[@class='name']\")\n",
    "    price =driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    " \n",
    "    for j  in b_name:\n",
    "        B_name.append(j.text)\n",
    "    B_name[:100]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in p_desc:\n",
    "        P_desc.append(k.text)\n",
    "    P_desc[:100] \n",
    "    \n",
    "    \n",
    "    for l in price:\n",
    "        Price.append(l.text)\n",
    "    Price[:100] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3d7a9ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(B_name[:100])),print(len(Price[:100])),print(len(P_desc[:100]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed98373b",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644dd5ba",
   "metadata": {},
   "source": [
    "Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a3278b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\arti\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "071828b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\" https://www.amazon.in \"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "9765ca08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"39b27711f84d94fd6ae33f01974dc4e7\", element=\"9dcb3ec4-79ae-48ca-8396-bce6b5b2831d\")>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding element for job search bar\n",
    "search_g= driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "search_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "44190472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write on search bar\n",
    "search_g.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "65760f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"39b27711f84d94fd6ae33f01974dc4e7\", element=\"a4b0e696-c116-4616-9d21-7c7a7df4df6a\")>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"//input[@id='nav-search-submit-button']\")\n",
    "search_btn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "37eabf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn=driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6ac1d",
   "metadata": {},
   "source": [
    "Only one core shown on the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9a7e8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Price=[]\n",
    "Rating=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "366c02df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    b_name=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    p_desc=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    price =driver.find_elements_by_xpath(\"//div[@class='_25b18c']\")\n",
    "    \n",
    "    \n",
    "    for j  in b_name:\n",
    "        Title.append(j.text)\n",
    "    Title[:10]    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for k in p_desc:\n",
    "        P_desc.append(k.text)\n",
    "    P_desc[:10] \n",
    "    \n",
    "    \n",
    "    for l in price:\n",
    "        Price.append(l.text)\n",
    "    Price[:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e791ced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(B_name[:10])),print(len(Price[:10])),print(len(P_desc[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b1ce2545",
   "metadata": {},
   "outputs": [],
   "source": [
    "sun_gl=pd.DataFrame({})\n",
    "sun_gl['Brand_name']=B_name[:10]\n",
    "sun_gl['P_price']=Price[:10]\n",
    "sun_gl['Pr_desc']=P_desc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3b3a80c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_name</th>\n",
       "      <th>P_price</th>\n",
       "      <th>Pr_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Brand_name, P_price, Pr_desc]\n",
       "Index: []"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sun_gl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d3428",
   "metadata": {},
   "source": [
    "# question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e9fccf",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "29e5a51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets first connect to the web driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\arti\\Downloads\\chromedriver_win32\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "5485da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ambitionbox.com/\"\n",
    "driver.get(url)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
